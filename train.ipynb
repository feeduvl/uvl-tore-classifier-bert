{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import shutil\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.config_store import ConfigStore\n",
    "import mlflow\n",
    "from src.experiments.sner import sner\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s:%(message)s\",\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%I:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_experiments=True\n",
      "pin_commits=True\n"
     ]
    }
   ],
   "source": [
    "sentence_length = 110\n",
    "\n",
    "run_experiments = os.getenv(\"UVL_BERT_RUN_EXPERIMENTS\",\"True\") == \"FALSE\"\n",
    "pin_commits = os.getenv(\"UVL_BERT_PIN_COMMITS\",\"True\") == \"FALSE\"\n",
    "\n",
    "print(f\"{run_experiments=}\")\n",
    "print(f\"{pin_commits=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tooling.config import Experiment, Transformation\n",
    "\n",
    "base_experiment_config = Experiment(\n",
    "    name=\"Base Config\", iterations=1, force=False\n",
    ")\n",
    "\n",
    "levels_transformation_config = Transformation(\n",
    "    description=\"Levels\",\n",
    "    type=\"Reduced\",\n",
    "    task=\"Domain_Level\",\n",
    "    domain_data=\"Domain_Level\",\n",
    "    activity=\"Domain_Level\",\n",
    "    stakeholder=\"Domain_Level\",\n",
    "    system_function=\"Interaction_Level\",\n",
    "    interaction=\"Interaction_Level\",\n",
    "    interaction_data=\"Interaction_Level\",\n",
    "    workspace=\"Interaction_Level\",\n",
    "    software=\"System_Level\",\n",
    "    internal_action=\"System_Level\",\n",
    "    internal_data=\"System_Level\",\n",
    ")\n",
    "\n",
    "label_transformation_config = Transformation(\n",
    "    description=\"None\",\n",
    "    type=\"Full\",\n",
    "    task=\"Task\",\n",
    "    domain_data=\"Domain_Data\",\n",
    "    activity=\"Activity\",\n",
    "    stakeholder=\"Stakeholder\",\n",
    "    system_function=\"System_Function\",\n",
    "    interaction=\"Interaction\",\n",
    "    interaction_data=\"Interaction_Data\",\n",
    "    workspace=\"Workspace\",\n",
    "    software=\"System_Level\",\n",
    "    internal_action=\"System_Level\",\n",
    "    internal_data=\"System_Level\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:01:57 INFO:Hint Label2Id: hint_label2id={'0': 0, 'Domain_Level': 1, 'Interaction_Level': 2, 'System_Level': 3}\n",
      "03:01:57 INFO:Hint Label2Id: hint_label2id={'0': 0, 'Task': 1, 'Domain_Data': 2, 'Activity': 3, 'Stakeholder': 4, 'System_Function': 5, 'Interaction': 6, 'Interaction_Data': 7, 'Workspace': 8, 'System_Level': 9}\n"
     ]
    }
   ],
   "source": [
    "from tooling.transformation import get_hint_transformation\n",
    "import pickle\n",
    "\n",
    "hint_transformation = get_hint_transformation(\n",
    "    transformation_cfg=OmegaConf.structured(levels_transformation_config)\n",
    ")\n",
    "hint_label2id = hint_transformation[\"label2id\"]\n",
    "pickle.dump(\n",
    "    hint_label2id, open(\"./src/service/models/hint_label2id.pickle\", \"wb\")\n",
    ")\n",
    "hint_id2label = {y: x for x, y in hint_label2id.items()}\n",
    "pickle.dump(\n",
    "    hint_id2label, open(\"./src/service/models/hint_id2label.pickle\", \"wb\")\n",
    ")\n",
    "\n",
    "transformation = get_hint_transformation(\n",
    "    transformation_cfg=OmegaConf.structured(label_transformation_config)\n",
    ")\n",
    "label2id = transformation[\"label2id\"]\n",
    "pickle.dump(label2id, open(\"./src/service/models/label2id.pickle\", \"wb\"))\n",
    "id2label = {y: x for x, y in label2id.items()}\n",
    "pickle.dump(id2label, open(\"./src/service/models/id2label.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BiLSTM First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:01:59 INFO:\n",
      "bilstm:\n",
      "  type: BiLSTM\n",
      "  sentence_length: 110\n",
      "  batch_size: 32\n",
      "  number_epochs: 4\n",
      "  verbose: 1\n",
      "  weighted_classes: false\n",
      "  learning_rate: 0.0001\n",
      "experiment:\n",
      "  name: 'Production: BiLSTM Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Domain_Level\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "03:02:00 INFO:New experiment. Running\n",
      "03:02:00 INFO:Entering mlflow context\n",
      "03:02:01 INFO:Created a temporary directory at /var/folders/82/x_tg3xgx1px781gb8v4bny1r0000gn/T/tmpm5oqqqf7\n",
      "03:02:01 INFO:Writing /var/folders/82/x_tg3xgx1px781gb8v4bny1r0000gn/T/tmpm5oqqqf7/_remote_module_non_scriptable.py\n",
      "03:02:01 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "03:02:02 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "03:02:02 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "03:02:04 INFO:Dataset Labels: transformed_dataset['labels']=['System_Level', 'Domain_Level', '0', 'Interaction_Level']\n",
      "03:02:04 INFO:Configured maximal sentence length: sentence_length = 110\n",
      "03:02:04 INFO:Class weights: {'0': 1.0, 'Domain_Level': 1.0, 'Interaction_Level': 1.0, 'System_Level': 1.0}\n",
      "03:02:04 INFO:loading projection weights from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz\n",
      "03:02:39 INFO:KeyedVectors lifecycle event {'msg': 'loaded (1193514, 100) matrix of type float32 from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-08-15T15:02:39.392570', 'gensim': '4.3.1', 'python': '3.11.4 (main, Jun 20 2023, 19:14:10) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n",
      "03:02:41 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/likeable-calf-64/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/likeable-calf-64/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/likeable-calf-64/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/likeable-calf-64/0_data_test.csv')]\n",
      "03:02:41 INFO:Starting iteration=0\n",
      "2023-08-15 15:02:41.275305: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-08-15 15:02:41.275327: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-08-15 15:02:41.275336: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-08-15 15:02:41.275367: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-15 15:02:41.275385: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "34/34 [==============================] - 7s 179ms/step - loss: 1.2253 - precision: 0.3540 - recall: 0.3506 - val_loss: 1.0727 - val_precision: 0.3172 - val_recall: 0.3333\n",
      "Epoch 2/4\n",
      "34/34 [==============================] - 6s 170ms/step - loss: 0.7066 - precision: 0.3172 - recall: 0.3333 - val_loss: 0.2058 - val_precision: 0.3172 - val_recall: 0.3333\n",
      "Epoch 3/4\n",
      "34/34 [==============================] - 6s 173ms/step - loss: 0.1820 - precision: 0.3172 - recall: 0.3333 - val_loss: 0.1667 - val_precision: 0.3172 - val_recall: 0.3333\n",
      "Epoch 4/4\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 0.1599 - precision: 0.3172 - recall: 0.3333 - val_loss: 0.1521 - val_precision: 0.3172 - val_recall: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:03:13 INFO:Assets written to: /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/bilstm/likeable-calf-64/0_model/assets\n",
      "2023-08-15 15:03:22.876339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:03:22.991861: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:03:23.004884: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:03:23.055586: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:03:23.067091: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:03:23 INFO:Logged iteration result res.precision=0.18282600526118 res.recall=0.25\n",
      "03:03:23 INFO:Finished iteration=0\n",
      "03:03:23 INFO:Breaking early after iteration=0 of 5 folds\n",
      "03:03:24 INFO:Logged experiment result res.mean_precision=0.18282600526118 res.mean_recall=0.25\n",
      "03:03:24 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "941f08130ff84d11bf2c80fc13790a81\n",
      "mlflow-artifacts:/32/727a82c476c8414f84827ef1b521d28f/artifacts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bilstm')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BiLSTMConfig, BiLSTM\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bilstm_experiment_config = deepcopy(base_experiment_config)\n",
    "bilstm_experiment_config.name = \"Production: BiLSTM Train for Staged Application\"\n",
    "\n",
    "bilstm_config = BiLSTM(sentence_length=sentence_length)\n",
    "\n",
    "bilstm_cfg: BiLSTMConfig = OmegaConf.structured(\n",
    "    BiLSTMConfig(\n",
    "        bilstm=bilstm_config,\n",
    "        experiment=bilstm_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "#bilstm_cfg.experiment.force = True\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bilstm import bilstm\n",
    "    bilstm(bilstm_cfg)\n",
    "\n",
    "\n",
    "bilstm_run_id = get_run_id(bilstm_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bilstm_run_id)\n",
    "\n",
    "print(mlflow.get_artifact_uri())\n",
    "\n",
    "bilstm_run = mlflow.get_run(bilstm_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bilstm_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bilstm\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bilstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SNER First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:03:26 INFO:\n",
      "sner:\n",
      "  type: SNER\n",
      "experiment:\n",
      "  name: 'Production: SNER Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Domain_Level\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "03:03:27 INFO:New experiment. Running\n",
      "03:03:27 INFO:Entering mlflow context\n",
      "03:03:27 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "03:03:27 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "03:03:28 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "03:03:29 INFO:Dataset Labels: transformed_dataset['labels']=['System_Level', 'Domain_Level', '0', 'Interaction_Level']\n",
      "03:03:31 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-slug-533/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-slug-533/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-slug-533/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-slug-533/0_data_test.csv')]\n",
      "03:03:31 INFO:Starting iteration=0\n",
      "03:03:32 INFO:Created train file for iteration=0, stored at filepath=PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/abrasive-slug-533/0_sner_train_file.txt')\n",
      "03:03:32 INFO:Created config file for iteration=0, stored at filepath=PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/abrasive-slug-533/0_sner_config_file.prop')\n",
      "03:03:32 INFO:Starting training, only printing every 10. line.\n",
      "03:03:32 INFO:useDisjunctive=true\n",
      "\n",
      "03:03:32 INFO:useTypeSeqs=true\n",
      "\n",
      "03:03:33 INFO:numDatums: 21285\n",
      "\n",
      "03:03:33 INFO:SCALING        <D> Diagonal scaling was used; <I> Scaled Identity\n",
      "\n",
      "03:03:33 INFO:{RELNORM}      The ratio of the current to initial gradient norms\n",
      "\n",
      "03:03:33 INFO:Iter 5 evals 7 <D> [M 1,000E0] 1,468E5 0,46s |5,143E3| {1,721E-1} 2,581E-2 - \n",
      "\n",
      "03:03:34 INFO:Iter 15 evals 17 <D> [M 1,000E0] 1,035E5 1,13s |1,720E3| {5,753E-2} 3,903E-2 - \n",
      "\n",
      "03:03:35 INFO:Iter 25 evals 27 <D> [M 1,000E0] 2,399E4 1,89s |8,998E2| {3,010E-2} 2,880E-1 - \n",
      "\n",
      "03:03:36 INFO:Iter 35 evals 38 <D> [1M 1,895E-1] 7,535E3 2,87s |6,402E2| {2,142E-2} 1,703E-1 - \n",
      "\n",
      "03:03:37 INFO:Iter 45 evals 50 <D> [M 1,000E0] 2,985E3 3,87s |2,907E2| {9,724E-3} 1,258E-1 - \n",
      "\n",
      "03:03:38 INFO:Iter 55 evals 60 <D> [M 1,000E0] 1,727E3 4,83s |2,045E2| {6,840E-3} 6,177E-2 - \n",
      "\n",
      "03:03:39 INFO:Iter 65 evals 72 <D> [M 1,000E0] 1,479E3 5,88s |5,088E1| {1,702E-3} 1,281E-2 - \n",
      "\n",
      "03:03:40 INFO:Iter 75 evals 83 <D> [M 1,000E0] 1,415E3 6,89s |3,461E1| {1,158E-3} 3,622E-3 - \n",
      "\n",
      "03:03:41 INFO:Iter 85 evals 93 <D> [1M 2,868E-1] 1,402E3 7,88s |2,023E1| {6,769E-4} 8,189E-4 - \n",
      "\n",
      "03:03:42 INFO:Iter 95 evals 105 <D> [1M 3,490E-1] 1,398E3 8,91s |1,361E1| {4,552E-4} 2,132E-4 - \n",
      "\n",
      "03:03:43 INFO:Iter 105 evals 117 <D> [M 1,000E0] 1,396E3 9,91s |4,776E0| {1,598E-4} 1,081E-4 - \n",
      "\n",
      "03:03:45 INFO:Trained model for iteration=0, stored at filepath=PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/abrasive-slug-533/0_model.ser.gz')\n",
      "03:03:45 INFO:Logged classification results for iteration 0 at /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/abrasive-slug-533/0_classification_result.pickle, /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/abrasive-slug-533/0_classification_result.csv\n",
      "03:03:46 INFO:Logged solutions for iteration 0 at /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/abrasive-slug-533/0_solution.pickle, /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/abrasive-slug-533/0_solution.csv\n",
      "03:03:46 INFO:Logged iteration result res.precision=0.822690910664297 res.recall=0.7691307822081903\n",
      "03:03:46 INFO:Finished iteration=0\n",
      "03:03:46 INFO:Breaking early after iteration=0 of 5 folds\n",
      "03:03:47 INFO:Logged experiment result res.mean_precision=0.822690910664297 res.mean_recall=0.7691307822081903\n",
      "03:03:47 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow-artifacts:/32/727a82c476c8414f84827ef1b521d28f/artifacts\n",
      "5ffff0522cb140cb85d6c0a402b2bd43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/sner.ser.gz')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import SNERConfig, SNER\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "sner_experiment_config = deepcopy(base_experiment_config)\n",
    "sner_experiment_config.name = \"Production: SNER Train for Staged Application\"\n",
    "\n",
    "sner_config = SNER()\n",
    "\n",
    "sner_cfg = OmegaConf.structured(\n",
    "    SNERConfig(\n",
    "        sner=sner_config,\n",
    "        experiment=sner_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.sner import sner\n",
    "    sner(OmegaConf.create(sner_cfg))\n",
    "\n",
    "sner_run_id = get_run_id(sner_cfg, pin_commit = pin_commits)\n",
    "print(mlflow.get_artifact_uri())\n",
    "print(sner_run_id)\n",
    "\n",
    "sner_run = mlflow.get_run(sner_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{sner_run.info.artifact_uri}/0_model.ser.gz\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    Path(\"./src/service/models/sner.ser.gz\").unlink()\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model.ser.gz\").rename(\n",
    "    \"./src/service/models/sner.ser.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:03:48 INFO:\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "experiment:\n",
      "  name: 'Production: BERT_1 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Domain_Level\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "03:03:48 INFO:New experiment. Running\n",
      "03:03:48 INFO:Entering mlflow context\n",
      "03:03:49 INFO:Using device: mps\n",
      "03:03:49 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "03:03:49 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "03:03:49 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "03:03:51 INFO:Dataset Labels: transformed_dataset['labels']=['System_Level', 'Domain_Level', '0', 'Interaction_Level']\n",
      "03:03:51 INFO:Class weights: {'0': 1.0, 'Domain_Level': 1.0, 'Interaction_Level': 1.0, 'System_Level': 1.0}\n",
      "03:03:52 INFO:Configured maximal token sequence length: max_len = 110\n",
      "03:03:53 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/secretive-gull-251/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/secretive-gull-251/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/secretive-gull-251/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/secretive-gull-251/0_data_test.csv')]\n",
      "03:03:53 INFO:Starting iteration=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8309cfe5d04602b1a443caf9f397f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da58d835a43e4080aab168e6bfca6e7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:04:23 INFO:Logged iteration result res.precision=0.8544484579644434 res.recall=0.7748789828781871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28557825088500977, 'eval_step': 0, 'eval_precision': 0.8544484579644434, 'eval_recall': 0.7748789828781871, 'eval_label_count': 4, 'eval_runtime': 2.2206, 'eval_samples_per_second': 121.14, 'eval_steps_per_second': 4.053, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:04:52 INFO:Logged iteration result res.precision=0.8574516379667173 res.recall=0.8008700534098114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26236972212791443, 'eval_step': 2, 'eval_precision': 0.8574516379667173, 'eval_recall': 0.8008700534098114, 'eval_label_count': 4, 'eval_runtime': 2.1802, 'eval_samples_per_second': 123.382, 'eval_steps_per_second': 4.128, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:05:22 INFO:Logged iteration result res.precision=0.8546933418222866 res.recall=0.814459573814639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2621402442455292, 'eval_step': 4, 'eval_precision': 0.8546933418222866, 'eval_recall': 0.814459573814639, 'eval_label_count': 4, 'eval_runtime': 2.1059, 'eval_samples_per_second': 127.738, 'eval_steps_per_second': 4.274, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:05:51 INFO:Logged iteration result res.precision=0.851239252202505 res.recall=0.8274067665169053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.26578184962272644, 'eval_step': 6, 'eval_precision': 0.851239252202505, 'eval_recall': 0.8274067665169053, 'eval_label_count': 4, 'eval_runtime': 2.0944, 'eval_samples_per_second': 128.438, 'eval_steps_per_second': 4.297, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:20 INFO:Logged iteration result res.precision=0.8494281543896238 res.recall=0.8229801390592925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2659144103527069, 'eval_step': 8, 'eval_precision': 0.8494281543896238, 'eval_recall': 0.8229801390592925, 'eval_label_count': 4, 'eval_runtime': 2.0603, 'eval_samples_per_second': 130.562, 'eval_steps_per_second': 4.368, 'epoch': 5.0}\n",
      "{'train_runtime': 148.1275, 'train_samples_per_second': 36.286, 'train_steps_per_second': 1.148, 'train_loss': 0.22822191574994255, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:06:26 INFO:Logged iteration result res.precision=0.8546933418222866 res.recall=0.814459573814639\n",
      "03:06:26 INFO:Logged iteration result res.precision=0.8546933418222866 res.recall=0.814459573814639\n",
      "03:06:26 INFO:Finished iteration=0\n",
      "03:06:26 INFO:Logging model artifact (might take a while)\n",
      "03:08:01 INFO:Breaking early after iteration=0 of 5 folds\n",
      "03:08:02 INFO:Logged experiment result res.mean_precision=0.8546933418222866 res.mean_recall=0.814459573814639\n",
      "03:08:02 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "f403ed360ab84762857c70de2ab3c26f\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BERTConfig, BERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_1_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_1_experiment_config.name = \"Production: BERT_1 Train for Staged Application\"\n",
    "\n",
    "bert_1_config = BERT(max_len=sentence_length)\n",
    "\n",
    "bert_1_cfg = OmegaConf.structured(\n",
    "    BERTConfig(\n",
    "        bert=bert_1_config,\n",
    "        experiment=bert_1_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bert import bert\n",
    "    bert(OmegaConf.create(bert_1_cfg))\n",
    "\n",
    "bert_1_run_id = get_run_id(bert_1_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_1_run_id)\n",
    "\n",
    "bert_1_run = mlflow.get_run(bert_1_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_1_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_1\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for BERT First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:08:19 INFO:\n",
      "first_model_bert:\n",
      "  bert:\n",
      "    model: bert-base-uncased\n",
      "    type: BERT\n",
      "    max_len: 110\n",
      "    train_batch_size: 32\n",
      "    validation_batch_size: 32\n",
      "    number_epochs: 5\n",
      "    learning_rate_bert: 2.0e-05\n",
      "    learning_rate_classifier: 0.01\n",
      "    weight_decay: 0.01\n",
      "    weighted_classes: false\n",
      "  experiment:\n",
      "    name: 'Production: BERT_1 Train for Staged Application'\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Domain_Level\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "first_model_bilstm: null\n",
      "first_model_sner: null\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: 'Production: BERT_2 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "\n",
      "03:08:20 INFO:New experiment. Running\n",
      "03:08:20 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:08:20 INFO:Using device: mps\n",
      "03:08:20 INFO:Found existing run with run_id: f403ed360ab84762857c70de2ab3c26f matching the configuration\n",
      "03:08:20 INFO:Downloading run model from mlflow-artifacts:/34/f403ed360ab84762857c70de2ab3c26f/artifacts/0_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:08:38 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "03:08:38 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "03:08:39 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "03:08:41 INFO:Dataset Labels: transformed_dataset['labels']=['Activity', 'Task', 'Interaction', 'Domain_Data', 'Stakeholder', 'System_Level', '0', 'Interaction_Data', 'System_Function', 'Workspace']\n",
      "03:08:41 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "03:08:41 INFO:Configured maximal token sequence length: max_len = 110\n",
      "03:08:43 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/rebellious-rat-364/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/rebellious-rat-364/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/rebellious-rat-364/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/rebellious-rat-364/0_data_test.csv')]\n",
      "03:08:43 INFO:Starting iteration=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc2b6a3b3dcb4b759067e35d68fdbda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:08:43 INFO:Loading Model\n",
      "03:08:43 INFO:Using device: mps\n",
      "03:08:44 INFO:Creating hint column\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f1a8276f8f4349bf3ac10bc86caf1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a349f460d73440e9f0c3c7f652d5f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:09:17 INFO:Loading Model\n",
      "03:09:18 INFO:Using device: mps\n",
      "03:09:18 INFO:Creating hint column\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8cabe2add649da838adf6a969734cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:09:56 INFO:Logged iteration result res.precision=0.6649939532038388 res.recall=0.6293377921050721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3836483359336853, 'eval_step': 0, 'eval_precision': 0.6649939532038388, 'eval_recall': 0.6293377921050721, 'eval_label_count': 10, 'eval_runtime': 2.192, 'eval_samples_per_second': 122.719, 'eval_steps_per_second': 4.106, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:10:25 INFO:Logged iteration result res.precision=0.6912975512072935 res.recall=0.6401838993784642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3642183542251587, 'eval_step': 2, 'eval_precision': 0.6912975512072935, 'eval_recall': 0.6401838993784642, 'eval_label_count': 10, 'eval_runtime': 2.1036, 'eval_samples_per_second': 127.873, 'eval_steps_per_second': 4.278, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:10:54 INFO:Logged iteration result res.precision=0.7253131652617635 res.recall=0.6769705769319452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3512852191925049, 'eval_step': 4, 'eval_precision': 0.7253131652617635, 'eval_recall': 0.6769705769319452, 'eval_label_count': 10, 'eval_runtime': 2.108, 'eval_samples_per_second': 127.608, 'eval_steps_per_second': 4.269, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:11:24 INFO:Logged iteration result res.precision=0.7001782689141283 res.recall=0.649182081115905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3634724020957947, 'eval_step': 6, 'eval_precision': 0.7001782689141283, 'eval_recall': 0.649182081115905, 'eval_label_count': 10, 'eval_runtime': 2.088, 'eval_samples_per_second': 128.832, 'eval_steps_per_second': 4.31, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:11:53 INFO:Logged iteration result res.precision=0.6977754424758543 res.recall=0.6524043185844804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36366942524909973, 'eval_step': 8, 'eval_precision': 0.6977754424758543, 'eval_recall': 0.6524043185844804, 'eval_label_count': 10, 'eval_runtime': 2.1102, 'eval_samples_per_second': 127.474, 'eval_steps_per_second': 4.265, 'epoch': 5.0}\n",
      "{'train_runtime': 147.9124, 'train_samples_per_second': 36.339, 'train_steps_per_second': 1.149, 'train_loss': 0.30330666934742645, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:11:59 INFO:Logged iteration result res.precision=0.7253131652617635 res.recall=0.6769705769319452\n",
      "03:11:59 INFO:Logged iteration result res.precision=0.7253131652617635 res.recall=0.6769705769319452\n",
      "03:11:59 INFO:Finished iteration=0\n",
      "03:11:59 INFO:Logging model artifact (might take a while)\n",
      "03:13:38 INFO:Breaking early after iteration=0 of 5 folds\n",
      "03:13:39 INFO:Logged experiment result res.mean_precision=0.7253131652617635 res.mean_recall=0.6769705769319452\n",
      "03:13:39 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "220b9b3b1da94ca6a16a23e0b1da5807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_bert')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_bert_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_bert_experiment_config.name = \"Production: BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_bert_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_bert_cfg: DualModelStagedBERTConfig = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_bert_config,\n",
    "        experiment=bert_2_bert_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_bert=bert_1_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_bert_cfg))\n",
    "\n",
    "bert_2_bert_run_id = get_run_id(bert_2_bert_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_bert_run_id)\n",
    "\n",
    "bert_2_bert_run = mlflow.get_run(bert_2_bert_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_bert_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_bert\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_2_bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for SNER First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:13:56 INFO:\n",
      "first_model_bert: null\n",
      "first_model_bilstm: null\n",
      "first_model_sner:\n",
      "  sner:\n",
      "    type: SNER\n",
      "  experiment:\n",
      "    name: 'Production: SNER Train for Staged Application'\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Domain_Level\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: 'Production: BERT_2 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "\n",
      "03:13:57 INFO:New experiment. Running\n",
      "03:13:57 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:13:57 INFO:Using device: mps\n",
      "03:13:57 INFO:Found existing run with run_id: 5ffff0522cb140cb85d6c0a402b2bd43 matching the configuration\n",
      "03:13:57 INFO:Downloading run model from mlflow-artifacts:/33/5ffff0522cb140cb85d6c0a402b2bd43/artifacts/0_model.ser.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:13:58 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "03:13:59 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "03:13:59 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "03:14:01 INFO:Dataset Labels: transformed_dataset['labels']=['Activity', 'Task', 'Interaction', 'Domain_Data', 'Stakeholder', 'System_Level', '0', 'Interaction_Data', 'System_Function', 'Workspace']\n",
      "03:14:01 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "03:14:01 INFO:Configured maximal token sequence length: max_len = 110\n",
      "03:14:03 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/glamorous-shrew-88/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/glamorous-shrew-88/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/glamorous-shrew-88/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/glamorous-shrew-88/0_data_test.csv')]\n",
      "03:14:03 INFO:Starting iteration=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc98e88d4614a8bb4733abea8678ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b50dfafa271c418094c27613c87e2d12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:14:35 INFO:Logged iteration result res.precision=0.6754658112454573 res.recall=0.6221767408632006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3807818591594696, 'eval_step': 0, 'eval_precision': 0.6754658112454573, 'eval_recall': 0.6221767408632006, 'eval_label_count': 10, 'eval_runtime': 2.1577, 'eval_samples_per_second': 124.671, 'eval_steps_per_second': 4.171, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:15:05 INFO:Logged iteration result res.precision=0.7047199963616488 res.recall=0.6282298248503083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3546621799468994, 'eval_step': 2, 'eval_precision': 0.7047199963616488, 'eval_recall': 0.6282298248503083, 'eval_label_count': 10, 'eval_runtime': 2.3321, 'eval_samples_per_second': 115.349, 'eval_steps_per_second': 3.859, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:15:34 INFO:Logged iteration result res.precision=0.7206604419047202 res.recall=0.6598699192764179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34967726469039917, 'eval_step': 4, 'eval_precision': 0.7206604419047202, 'eval_recall': 0.6598699192764179, 'eval_label_count': 10, 'eval_runtime': 2.0767, 'eval_samples_per_second': 129.53, 'eval_steps_per_second': 4.334, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:16:03 INFO:Logged iteration result res.precision=0.6775542651639498 res.recall=0.6242105269039968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36373209953308105, 'eval_step': 6, 'eval_precision': 0.6775542651639498, 'eval_recall': 0.6242105269039968, 'eval_label_count': 10, 'eval_runtime': 2.0673, 'eval_samples_per_second': 130.124, 'eval_steps_per_second': 4.354, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:16:32 INFO:Logged iteration result res.precision=0.6856046373502331 res.recall=0.631763855984542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36506086587905884, 'eval_step': 8, 'eval_precision': 0.6856046373502331, 'eval_recall': 0.631763855984542, 'eval_label_count': 10, 'eval_runtime': 2.0793, 'eval_samples_per_second': 129.371, 'eval_steps_per_second': 4.328, 'epoch': 5.0}\n",
      "{'train_runtime': 146.8901, 'train_samples_per_second': 36.592, 'train_steps_per_second': 1.157, 'train_loss': 0.24524720135857078, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:16:37 INFO:Logged iteration result res.precision=0.7206604419047202 res.recall=0.6598699192764179\n",
      "03:16:38 INFO:Logged iteration result res.precision=0.7206604419047202 res.recall=0.6598699192764179\n",
      "03:16:38 INFO:Finished iteration=0\n",
      "03:16:38 INFO:Logging model artifact (might take a while)\n",
      "03:18:14 INFO:Breaking early after iteration=0 of 5 folds\n",
      "03:18:15 INFO:Logged experiment result res.mean_precision=0.7206604419047202 res.mean_recall=0.6598699192764179\n",
      "03:18:15 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "c238264bed8e400a8ef4bf9f2e5d47e5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_sner')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_sner_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_sner_experiment_config.name = \"Production: BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_sner_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_sner_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_sner_config,\n",
    "        experiment=bert_2_sner_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_sner=sner_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_sner_cfg))\n",
    "\n",
    "bert_2_sner_run_id = get_run_id(bert_2_sner_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_sner_run_id)\n",
    "\n",
    "bert_2_sner_run = mlflow.get_run(bert_2_sner_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_sner_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_sner\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_2_sner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for BILSTM First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:18:34 INFO:\n",
      "first_model_bert: null\n",
      "first_model_bilstm:\n",
      "  bilstm:\n",
      "    type: BiLSTM\n",
      "    sentence_length: 110\n",
      "    batch_size: 32\n",
      "    number_epochs: 4\n",
      "    verbose: 1\n",
      "    weighted_classes: false\n",
      "    learning_rate: 0.0001\n",
      "  experiment:\n",
      "    name: 'Production: BiLSTM Train for Staged Application'\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Domain_Level\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "first_model_sner: null\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: 'Production: BERT_2 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "\n",
      "03:18:35 INFO:New experiment. Running\n",
      "03:18:35 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:18:35 INFO:Using device: mps\n",
      "03:18:35 INFO:Found existing run with run_id: 941f08130ff84d11bf2c80fc13790a81 matching the configuration\n",
      "03:18:35 INFO:Downloading run model from mlflow-artifacts:/32/941f08130ff84d11bf2c80fc13790a81/artifacts/0_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:18:38 INFO:loading projection weights from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz\n",
      "03:19:12 INFO:KeyedVectors lifecycle event {'msg': 'loaded (1193514, 100) matrix of type float32 from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-08-15T15:19:12.741889', 'gensim': '4.3.1', 'python': '3.11.4 (main, Jun 20 2023, 19:14:10) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n",
      "03:19:12 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "03:19:13 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "03:19:13 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "03:19:16 INFO:Dataset Labels: transformed_dataset['labels']=['Activity', 'Task', 'Interaction', 'Domain_Data', 'Stakeholder', 'System_Level', '0', 'Interaction_Data', 'System_Function', 'Workspace']\n",
      "03:19:16 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "03:19:16 INFO:Configured maximal token sequence length: max_len = 110\n",
      "03:19:17 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/nervous-roo-558/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/nervous-roo-558/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/nervous-roo-558/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/nervous-roo-558/0_data_test.csv')]\n",
      "03:19:17 INFO:Starting iteration=0\n",
      "2023-08-15 15:19:34.112474: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:19:34.230174: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:19:34.241882: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:19:34.302210: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/34 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 15:19:34.314787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 2s 28ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd591f9a27254ab290aeed36184ada3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 15:19:41.982154: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:19:42.097192: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:19:42.109923: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:19:42.166341: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 15:19:42.177371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 35ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9709368d723c49888f90a5e824a362e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:20:12 INFO:Logged iteration result res.precision=0.6680461931378503 res.recall=0.6199965235756287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3932192921638489, 'eval_step': 0, 'eval_precision': 0.6680461931378503, 'eval_recall': 0.6199965235756287, 'eval_label_count': 10, 'eval_runtime': 2.1205, 'eval_samples_per_second': 126.857, 'eval_steps_per_second': 4.244, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:20:41 INFO:Logged iteration result res.precision=0.694559879687572 res.recall=0.6371689388907558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3638961613178253, 'eval_step': 2, 'eval_precision': 0.694559879687572, 'eval_recall': 0.6371689388907558, 'eval_label_count': 10, 'eval_runtime': 2.0829, 'eval_samples_per_second': 129.148, 'eval_steps_per_second': 4.321, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:21:10 INFO:Logged iteration result res.precision=0.7153252194444211 res.recall=0.6797689227191499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3512914776802063, 'eval_step': 4, 'eval_precision': 0.7153252194444211, 'eval_recall': 0.6797689227191499, 'eval_label_count': 10, 'eval_runtime': 2.0903, 'eval_samples_per_second': 128.688, 'eval_steps_per_second': 4.306, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:21:39 INFO:Logged iteration result res.precision=0.7014383003454555 res.recall=0.652794402312237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36357608437538147, 'eval_step': 6, 'eval_precision': 0.7014383003454555, 'eval_recall': 0.652794402312237, 'eval_label_count': 10, 'eval_runtime': 2.1168, 'eval_samples_per_second': 127.08, 'eval_steps_per_second': 4.252, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:22:09 INFO:Logged iteration result res.precision=0.7034568204569754 res.recall=0.6549527130478034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.362361878156662, 'eval_step': 8, 'eval_precision': 0.7034568204569754, 'eval_recall': 0.6549527130478034, 'eval_label_count': 10, 'eval_runtime': 2.0926, 'eval_samples_per_second': 128.549, 'eval_steps_per_second': 4.301, 'epoch': 5.0}\n",
      "{'train_runtime': 147.5346, 'train_samples_per_second': 36.432, 'train_steps_per_second': 1.152, 'train_loss': 0.31862718918744254, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:22:15 INFO:Logged iteration result res.precision=0.7153252194444211 res.recall=0.6797689227191499\n",
      "03:22:15 INFO:Logged iteration result res.precision=0.7153252194444211 res.recall=0.6797689227191499\n",
      "03:22:15 INFO:Finished iteration=0\n",
      "03:22:15 INFO:Logging model artifact (might take a while)\n",
      "03:23:52 INFO:Breaking early after iteration=0 of 5 folds\n",
      "03:23:53 INFO:Logged experiment result res.mean_precision=0.7153252194444211 res.mean_recall=0.6797689227191499\n",
      "03:23:53 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "4ece27d8e9c744df81556d3973aab532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_bilstm')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_bilstm_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_bilstm_experiment_config.name = \"Production: BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_bilstm_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_bilstm_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_bilstm_config,\n",
    "        experiment=bert_2_bilstm_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_bilstm=bilstm_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_bilstm_cfg))\n",
    "\n",
    "bert_2_bilstm_run_id = get_run_id(bert_2_bilstm_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_bilstm_run_id)\n",
    "\n",
    "bert_2_bilstm_run = mlflow.get_run(bert_2_bilstm_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_bilstm_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_bilstm\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\n",
    "    \"./src/service/models/bert_2_bilstm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT E2E Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:24:12 INFO:\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "experiment:\n",
      "  name: 'Production: BERT Train for E2E Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "03:24:12 INFO:New experiment. Running\n",
      "03:24:12 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:24:12 INFO:Using device: mps\n",
      "03:24:12 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "03:24:13 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "03:24:13 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "03:24:15 INFO:Dataset Labels: transformed_dataset['labels']=['Activity', 'Task', 'Interaction', 'Domain_Data', 'Stakeholder', 'System_Level', '0', 'Interaction_Data', 'System_Function', 'Workspace']\n",
      "03:24:15 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "03:24:15 INFO:Configured maximal token sequence length: max_len = 110\n",
      "03:24:17 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/awesome-tern-418/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/awesome-tern-418/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/awesome-tern-418/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/awesome-tern-418/0_data_test.csv')]\n",
      "03:24:17 INFO:Starting iteration=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560aed354d994d3191297a28beb01856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "103bcf76ef0a4ca5b6e0a06574ce61b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:24:45 INFO:Logged iteration result res.precision=0.6559464277421911 res.recall=0.6235245753039973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3921107351779938, 'eval_step': 0, 'eval_precision': 0.6559464277421911, 'eval_recall': 0.6235245753039973, 'eval_label_count': 10, 'eval_runtime': 2.3104, 'eval_samples_per_second': 116.433, 'eval_steps_per_second': 3.896, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:25:14 INFO:Logged iteration result res.precision=0.6939126772464025 res.recall=0.6356914400673643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36475953459739685, 'eval_step': 2, 'eval_precision': 0.6939126772464025, 'eval_recall': 0.6356914400673643, 'eval_label_count': 10, 'eval_runtime': 2.0802, 'eval_samples_per_second': 129.317, 'eval_steps_per_second': 4.327, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:25:43 INFO:Logged iteration result res.precision=0.7178643892293535 res.recall=0.6810540380395174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3499082624912262, 'eval_step': 4, 'eval_precision': 0.7178643892293535, 'eval_recall': 0.6810540380395174, 'eval_label_count': 10, 'eval_runtime': 2.139, 'eval_samples_per_second': 125.761, 'eval_steps_per_second': 4.208, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:26:12 INFO:Logged iteration result res.precision=0.7001814713233431 res.recall=0.653175018333902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3617035746574402, 'eval_step': 6, 'eval_precision': 0.7001814713233431, 'eval_recall': 0.653175018333902, 'eval_label_count': 10, 'eval_runtime': 2.1014, 'eval_samples_per_second': 128.01, 'eval_steps_per_second': 4.283, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:26:41 INFO:Logged iteration result res.precision=0.6996668614582978 res.recall=0.6556065767081019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3600035607814789, 'eval_step': 8, 'eval_precision': 0.6996668614582978, 'eval_recall': 0.6556065767081019, 'eval_label_count': 10, 'eval_runtime': 2.1107, 'eval_samples_per_second': 127.443, 'eval_steps_per_second': 4.264, 'epoch': 5.0}\n",
      "{'train_runtime': 145.6476, 'train_samples_per_second': 36.904, 'train_steps_per_second': 1.167, 'train_loss': 0.3214408874511719, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03:26:47 INFO:Logged iteration result res.precision=0.7178643892293535 res.recall=0.6810540380395174\n",
      "03:26:47 INFO:Logged iteration result res.precision=0.7178643892293535 res.recall=0.6810540380395174\n",
      "03:26:47 INFO:Finished iteration=0\n",
      "03:26:47 INFO:Logging model artifact (might take a while)\n",
      "03:28:23 INFO:Breaking early after iteration=0 of 5 folds\n",
      "03:28:24 INFO:Logged experiment result res.mean_precision=0.7178643892293535 res.mean_recall=0.6810540380395174\n",
      "03:28:24 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "6552cb782d6e4d1686666fd66e69e09a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BERTConfig, BERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_experiment_config.name = \"Production: BERT Train for E2E Application\"\n",
    "\n",
    "bert_config = BERT(max_len=sentence_length)\n",
    "\n",
    "bert_cfg = OmegaConf.structured(\n",
    "    BERTConfig(\n",
    "        bert=bert_config,\n",
    "        experiment=bert_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bert import bert\n",
    "    bert(OmegaConf.create(bert_cfg))\n",
    "\n",
    "bert_run_id = get_run_id(bert_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_run_id)\n",
    "\n",
    "run = mlflow.get_run(bert_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{run.info.artifact_uri}/0_model\", dst_path=Path(\"./src/service/models/\")\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
