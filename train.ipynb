{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import shutil\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.config_store import ConfigStore\n",
    "import mlflow\n",
    "from src.experiments.sner import sner\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s:%(message)s\",\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%I:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_experiments=False\n",
      "pin_commits=False\n"
     ]
    }
   ],
   "source": [
    "sentence_length = 110\n",
    "\n",
    "run_experiments = os.getenv(\"UVL_BERT_RUN_EXPERIMENTS\",\"True\") == \"True\"\n",
    "pin_commits = os.getenv(\"UVL_BERT_PIN_COMMITS\",\"True\") == \"True\"\n",
    "\n",
    "print(f\"{run_experiments=}\")\n",
    "print(f\"{pin_commits=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tooling.config import Experiment, Transformation\n",
    "\n",
    "base_experiment_config = Experiment(\n",
    "    name=\"Base Config\", iterations=1, force=False\n",
    ")\n",
    "\n",
    "levels_transformation_config = Transformation(\n",
    "    description=\"Levels\",\n",
    "    type=\"Reduced\",\n",
    "    task=\"Domain_Level\",\n",
    "    domain_data=\"Domain_Level\",\n",
    "    activity=\"Activity\",\n",
    "    stakeholder=\"Domain_Level\",\n",
    "    system_function=\"Interaction_Level\",\n",
    "    interaction=\"Interaction_Level\",\n",
    "    interaction_data=\"Interaction_Level\",\n",
    "    workspace=\"Interaction_Level\",\n",
    "    software=\"System_Level\",\n",
    "    internal_action=\"System_Level\",\n",
    "    internal_data=\"System_Level\",\n",
    ")\n",
    "\n",
    "label_transformation_config = Transformation(\n",
    "    description=\"None\",\n",
    "    type=\"Full\",\n",
    "    task=\"Task\",\n",
    "    domain_data=\"Domain_Data\",\n",
    "    activity=\"Activity\",\n",
    "    stakeholder=\"Stakeholder\",\n",
    "    system_function=\"System_Function\",\n",
    "    interaction=\"Interaction\",\n",
    "    interaction_data=\"Interaction_Data\",\n",
    "    workspace=\"Workspace\",\n",
    "    software=\"System_Level\",\n",
    "    internal_action=\"System_Level\",\n",
    "    internal_data=\"System_Level\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:11:16 INFO:Hint Label2Id: hint_label2id={'0': 0, 'Activity': 1, 'Domain_Level': 2, 'Interaction_Level': 3, 'System_Level': 4}\n",
      "05:11:16 INFO:Hint Label2Id: hint_label2id={'0': 0, 'Task': 1, 'Domain_Data': 2, 'Activity': 3, 'Stakeholder': 4, 'System_Function': 5, 'Interaction': 6, 'Interaction_Data': 7, 'Workspace': 8, 'System_Level': 9}\n"
     ]
    }
   ],
   "source": [
    "from tooling.transformation import get_hint_transformation\n",
    "import pickle\n",
    "\n",
    "hint_transformation = get_hint_transformation(\n",
    "    transformation_cfg=OmegaConf.structured(levels_transformation_config)\n",
    ")\n",
    "hint_label2id = hint_transformation[\"label2id\"]\n",
    "pickle.dump(\n",
    "    hint_label2id, open(\"./src/service/models/hint_label2id.pickle\", \"wb\")\n",
    ")\n",
    "hint_id2label = {y: x for x, y in hint_label2id.items()}\n",
    "pickle.dump(\n",
    "    hint_id2label, open(\"./src/service/models/hint_id2label.pickle\", \"wb\")\n",
    ")\n",
    "\n",
    "transformation = get_hint_transformation(\n",
    "    transformation_cfg=OmegaConf.structured(label_transformation_config)\n",
    ")\n",
    "label2id = transformation[\"label2id\"]\n",
    "pickle.dump(label2id, open(\"./src/service/models/label2id.pickle\", \"wb\"))\n",
    "id2label = {y: x for x, y in label2id.items()}\n",
    "pickle.dump(id2label, open(\"./src/service/models/id2label.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BiLSTM First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:11:16 INFO:\n",
      "bilstm:\n",
      "  type: BiLSTM\n",
      "  sentence_length: 110\n",
      "  batch_size: 32\n",
      "  number_epochs: 32\n",
      "  verbose: 1\n",
      "  weighted_classes: false\n",
      "  learning_rate: 0.0001\n",
      "experiment:\n",
      "  name: 'Production: BiLSTM Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Activity\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "05:11:16 WARNING:Experiment was already run, aborting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e8af7ab5e4e4130890d3a77c57ef305\n",
      "mlflow-artifacts:/32/29b05fc08c354b1b8d999d8619a94c1a/artifacts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bilstm')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BiLSTMConfig, BiLSTM\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bilstm_experiment_config = deepcopy(base_experiment_config)\n",
    "bilstm_experiment_config.name = \"Production: BiLSTM Train for Staged Application\"\n",
    "\n",
    "bilstm_config = BiLSTM(sentence_length=sentence_length)\n",
    "\n",
    "bilstm_cfg = OmegaConf.structured(\n",
    "    BiLSTMConfig(\n",
    "        bilstm=bilstm_config,\n",
    "        experiment=bilstm_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bilstm import bilstm\n",
    "    bilstm(bilstm_cfg)\n",
    "\n",
    "\n",
    "bilstm_run_id = get_run_id(bilstm_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bilstm_run_id)\n",
    "\n",
    "print(mlflow.get_artifact_uri())\n",
    "\n",
    "bilstm_run = mlflow.get_run(bilstm_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bilstm_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bilstm\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bilstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SNER First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:11:18 INFO:\n",
      "sner:\n",
      "  type: SNER\n",
      "experiment:\n",
      "  name: 'Production: SNER Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Activity\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "05:11:18 WARNING:Experiment was already run, aborting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow-artifacts:/32/29b05fc08c354b1b8d999d8619a94c1a/artifacts\n",
      "da407759ccc948b39f21560b8b3633ed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/sner.ser.gz')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import SNERConfig, SNER\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "sner_experiment_config = deepcopy(base_experiment_config)\n",
    "sner_experiment_config.name = \"Production: SNER Train for Staged Application\"\n",
    "\n",
    "sner_config = SNER()\n",
    "\n",
    "sner_cfg = OmegaConf.structured(\n",
    "    SNERConfig(\n",
    "        sner=sner_config,\n",
    "        experiment=sner_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.sner import sner\n",
    "    sner(OmegaConf.create(sner_cfg))\n",
    "\n",
    "sner_run_id = get_run_id(sner_cfg, pin_commit = pin_commits)\n",
    "print(mlflow.get_artifact_uri())\n",
    "print(sner_run_id)\n",
    "\n",
    "sner_run = mlflow.get_run(sner_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{sner_run.info.artifact_uri}/0_model.ser.gz\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    Path(\"./src/service/models/sner.ser.gz\").unlink()\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model.ser.gz\").rename(\n",
    "    \"./src/service/models/sner.ser.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:11:19 INFO:\n",
      "bert:\n",
      "  model: bert-base-cased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "experiment:\n",
      "  name: 'Production: BERT_1 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Activity\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "05:11:19 WARNING:Experiment was already run, aborting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29bb8ff8724b4c7689ddc4f86bc27a7e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BERTConfig, BERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_1_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_1_experiment_config.name = \"Production: BERT_1 Train for Staged Application\"\n",
    "\n",
    "bert_1_config = BERT(max_len=sentence_length)\n",
    "\n",
    "bert_1_cfg = OmegaConf.structured(\n",
    "    BERTConfig(\n",
    "        bert=bert_1_config,\n",
    "        experiment=bert_1_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bert import bert\n",
    "    bert(OmegaConf.create(bert_1_cfg))\n",
    "\n",
    "bert_1_run_id = get_run_id(bert_1_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_1_run_id)\n",
    "\n",
    "bert_1_run = mlflow.get_run(bert_1_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_1_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_1\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for BERT First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:11:35 INFO:\n",
      "first_model_bert:\n",
      "  bert:\n",
      "    model: bert-base-cased\n",
      "    type: BERT\n",
      "    max_len: 110\n",
      "    train_batch_size: 32\n",
      "    validation_batch_size: 32\n",
      "    number_epochs: 5\n",
      "    learning_rate_bert: 2.0e-05\n",
      "    learning_rate_classifier: 0.01\n",
      "    weight_decay: 0.01\n",
      "    weighted_classes: false\n",
      "  experiment:\n",
      "    name: 'Production: BERT_1 Train for Staged Application'\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Activity\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "first_model_bilstm: null\n",
      "first_model_sner: null\n",
      "bert:\n",
      "  model: bert-base-cased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: 'Production: BERT_2 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "\n",
      "2023/08/02 17:11:35 INFO mlflow.tracking.fluent: Experiment with name 'Production: BERT_2 Train for Staged Application' does not exist. Creating a new experiment.\n",
      "05:11:35 INFO:New experiment. Running\n",
      "05:11:35 INFO:Entering mlflow context\n",
      "05:11:36 INFO:Using device: mps\n",
      "05:11:36 INFO:Found existing run with run_id: 29bb8ff8724b4c7689ddc4f86bc27a7e matching the configuration\n",
      "05:11:36 INFO:Downloading run model from mlflow-artifacts:/34/29bb8ff8724b4c7689ddc4f86bc27a7e/artifacts/0_model\n",
      "05:11:52 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "05:11:53 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "05:11:53 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "05:11:55 INFO:Dataset Labels: transformed_dataset['labels']=['0', 'System_Level', 'Domain_Data', 'System_Function', 'Workspace', 'Stakeholder', 'Task', 'Interaction_Data', 'Interaction', 'Activity']\n",
      "05:11:55 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "05:11:55 INFO:Configured maximal token sequence length: max_len = 110\n",
      "05:11:57 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/luminous-sponge-492/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/luminous-sponge-492/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/luminous-sponge-492/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/luminous-sponge-492/0_data_test.csv')]\n",
      "05:11:57 INFO:Starting iteration=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be6ad0e47d64a268252a95d20c4cd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:11:57 INFO:Loading Model\n",
      "05:11:58 INFO:Using device: mps\n",
      "05:11:58 INFO:Creating hint column\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9ea197a0934512bff6402e63456baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261bfa4470434488bf429f3d58d7e1c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:12:31 INFO:Loading Model\n",
      "05:12:31 INFO:Using device: mps\n",
      "05:12:31 INFO:Creating hint column\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975bdbda631342999ac3f3b2a27b9eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:13:09 INFO:Logged iteration result res.precision=0.6924829056420345 res.recall=0.6250889993612005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38054579496383667, 'eval_step': 0, 'eval_precision': 0.6924829056420345, 'eval_recall': 0.6250889993612005, 'eval_label_count': 10, 'eval_runtime': 2.274, 'eval_samples_per_second': 118.294, 'eval_steps_per_second': 3.958, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:13:38 INFO:Logged iteration result res.precision=0.7176411929761606 res.recall=0.6497450084963436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3579650819301605, 'eval_step': 2, 'eval_precision': 0.7176411929761606, 'eval_recall': 0.6497450084963436, 'eval_label_count': 10, 'eval_runtime': 2.1558, 'eval_samples_per_second': 124.778, 'eval_steps_per_second': 4.175, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:14:07 INFO:Logged iteration result res.precision=0.7253149408241828 res.recall=0.6636970557828414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3440052568912506, 'eval_step': 4, 'eval_precision': 0.7253149408241828, 'eval_recall': 0.6636970557828414, 'eval_label_count': 10, 'eval_runtime': 2.12, 'eval_samples_per_second': 126.886, 'eval_steps_per_second': 4.245, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:14:36 INFO:Logged iteration result res.precision=0.7222134163120035 res.recall=0.6539427636830889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35386863350868225, 'eval_step': 6, 'eval_precision': 0.7222134163120035, 'eval_recall': 0.6539427636830889, 'eval_label_count': 10, 'eval_runtime': 2.0851, 'eval_samples_per_second': 129.009, 'eval_steps_per_second': 4.316, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:15:06 INFO:Logged iteration result res.precision=0.7055078197135416 res.recall=0.6385707882619516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35849639773368835, 'eval_step': 8, 'eval_precision': 0.7055078197135416, 'eval_recall': 0.6385707882619516, 'eval_label_count': 10, 'eval_runtime': 2.1391, 'eval_samples_per_second': 125.751, 'eval_steps_per_second': 4.207, 'epoch': 5.0}\n",
      "{'train_runtime': 147.5138, 'train_samples_per_second': 36.437, 'train_steps_per_second': 1.152, 'train_loss': 0.30282772288602944, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:15:12 INFO:Logged iteration result res.precision=0.7253149408241828 res.recall=0.6636970557828414\n",
      "05:15:12 INFO:Logged iteration result res.precision=0.7253149408241828 res.recall=0.6636970557828414\n",
      "05:15:12 INFO:Finished iteration=0\n",
      "05:15:12 INFO:Logging model artifact (might take a while)\n",
      "05:16:49 INFO:Breaking early after iteration=0 of 5 folds\n",
      "05:16:50 INFO:Logged experiment result res.mean_precision=0.7253149408241828 res.mean_recall=0.6636970557828414\n",
      "05:16:50 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "829e2947b822448eb54b9914a42661cb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_bert')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_bert_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_bert_experiment_config.name = \"Production: BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_bert_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_bert_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_bert_config,\n",
    "        experiment=bert_2_bert_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_bert=bert_1_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_bert_cfg))\n",
    "\n",
    "bert_2_bert_run_id = get_run_id(bert_2_bert_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_bert_run_id)\n",
    "\n",
    "bert_2_bert_run = mlflow.get_run(bert_2_bert_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_bert_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_bert\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_2_bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for SNER First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:17:07 INFO:\n",
      "first_model_bert: null\n",
      "first_model_bilstm: null\n",
      "first_model_sner:\n",
      "  sner:\n",
      "    type: SNER\n",
      "  experiment:\n",
      "    name: 'Production: SNER Train for Staged Application'\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Activity\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "bert:\n",
      "  model: bert-base-cased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: 'Production: BERT_2 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "\n",
      "05:17:08 INFO:New experiment. Running\n",
      "05:17:08 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:17:08 INFO:Using device: mps\n",
      "05:17:08 INFO:Found existing run with run_id: da407759ccc948b39f21560b8b3633ed matching the configuration\n",
      "05:17:08 INFO:Downloading run model from mlflow-artifacts:/33/da407759ccc948b39f21560b8b3633ed/artifacts/0_model.ser.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:17:09 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "05:17:10 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "05:17:10 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "05:17:12 INFO:Dataset Labels: transformed_dataset['labels']=['0', 'System_Level', 'Domain_Data', 'System_Function', 'Workspace', 'Stakeholder', 'Task', 'Interaction_Data', 'Interaction', 'Activity']\n",
      "05:17:12 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "05:17:12 INFO:Configured maximal token sequence length: max_len = 110\n",
      "05:17:14 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/invincible-perch-160/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/invincible-perch-160/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/invincible-perch-160/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/invincible-perch-160/0_data_test.csv')]\n",
      "05:17:14 INFO:Starting iteration=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e512685deb4fba9f8e72da28a70cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ce38c52e5144e9afb95023992c74d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:17:47 INFO:Logged iteration result res.precision=0.6825549843102875 res.recall=0.6291847384547476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3771092891693115, 'eval_step': 0, 'eval_precision': 0.6825549843102875, 'eval_recall': 0.6291847384547476, 'eval_label_count': 10, 'eval_runtime': 2.1034, 'eval_samples_per_second': 127.886, 'eval_steps_per_second': 4.279, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:18:16 INFO:Logged iteration result res.precision=0.7121240275794619 res.recall=0.6453930494461505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3518255949020386, 'eval_step': 2, 'eval_precision': 0.7121240275794619, 'eval_recall': 0.6453930494461505, 'eval_label_count': 10, 'eval_runtime': 2.1471, 'eval_samples_per_second': 125.286, 'eval_steps_per_second': 4.192, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:18:48 INFO:Logged iteration result res.precision=0.7084352194004455 res.recall=0.6422433651162286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3443887233734131, 'eval_step': 4, 'eval_precision': 0.7084352194004455, 'eval_recall': 0.6422433651162286, 'eval_label_count': 10, 'eval_runtime': 2.1702, 'eval_samples_per_second': 123.953, 'eval_steps_per_second': 4.147, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:19:17 INFO:Logged iteration result res.precision=0.7244434683806757 res.recall=0.638946891933687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35324788093566895, 'eval_step': 6, 'eval_precision': 0.7244434683806757, 'eval_recall': 0.638946891933687, 'eval_label_count': 10, 'eval_runtime': 2.1175, 'eval_samples_per_second': 127.034, 'eval_steps_per_second': 4.25, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:19:47 INFO:Logged iteration result res.precision=0.7248829529708132 res.recall=0.6380788324940454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35927027463912964, 'eval_step': 8, 'eval_precision': 0.7248829529708132, 'eval_recall': 0.6380788324940454, 'eval_label_count': 10, 'eval_runtime': 2.1524, 'eval_samples_per_second': 124.976, 'eval_steps_per_second': 4.181, 'epoch': 5.0}\n",
      "{'train_runtime': 150.8063, 'train_samples_per_second': 35.642, 'train_steps_per_second': 1.127, 'train_loss': 0.24476580900304457, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:19:53 INFO:Logged iteration result res.precision=0.7084352194004455 res.recall=0.6422433651162286\n",
      "05:19:53 INFO:Logged iteration result res.precision=0.7084352194004455 res.recall=0.6422433651162286\n",
      "05:19:53 INFO:Finished iteration=0\n",
      "05:19:53 INFO:Logging model artifact (might take a while)\n",
      "05:21:31 INFO:Breaking early after iteration=0 of 5 folds\n",
      "05:21:32 INFO:Logged experiment result res.mean_precision=0.7084352194004455 res.mean_recall=0.6422433651162286\n",
      "05:21:32 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92fa04894b354683b8c90b755ceeac69\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_sner')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_sner_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_sner_experiment_config.name = \"Production: BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_sner_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_sner_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_sner_config,\n",
    "        experiment=bert_2_sner_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_sner=sner_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_sner_cfg))\n",
    "\n",
    "bert_2_sner_run_id = get_run_id(bert_2_sner_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_sner_run_id)\n",
    "\n",
    "bert_2_sner_run = mlflow.get_run(bert_2_sner_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_sner_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_sner\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_2_sner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for BILSTM First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:21:49 INFO:\n",
      "first_model_bert: null\n",
      "first_model_bilstm:\n",
      "  bilstm:\n",
      "    type: BiLSTM\n",
      "    sentence_length: 110\n",
      "    batch_size: 32\n",
      "    number_epochs: 32\n",
      "    verbose: 1\n",
      "    weighted_classes: false\n",
      "    learning_rate: 0.0001\n",
      "  experiment:\n",
      "    name: 'Production: BiLSTM Train for Staged Application'\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Activity\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "first_model_sner: null\n",
      "bert:\n",
      "  model: bert-base-cased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: 'Production: BERT_2 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "\n",
      "05:21:49 INFO:New experiment. Running\n",
      "05:21:49 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:21:49 INFO:Using device: mps\n",
      "05:21:49 INFO:Found existing run with run_id: 5e8af7ab5e4e4130890d3a77c57ef305 matching the configuration\n",
      "05:21:49 INFO:Downloading run model from mlflow-artifacts:/32/5e8af7ab5e4e4130890d3a77c57ef305/artifacts/0_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:21:51 INFO:loading projection weights from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz\n",
      "05:22:26 INFO:KeyedVectors lifecycle event {'msg': 'loaded (1193514, 100) matrix of type float32 from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-08-02T17:22:26.990406', 'gensim': '4.3.1', 'python': '3.11.4 (main, Jun 20 2023, 19:14:10) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n",
      "05:22:27 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "05:22:27 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "05:22:27 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "05:22:30 INFO:Dataset Labels: transformed_dataset['labels']=['0', 'System_Level', 'Domain_Data', 'System_Function', 'Workspace', 'Stakeholder', 'Task', 'Interaction_Data', 'Interaction', 'Activity']\n",
      "05:22:30 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "05:22:30 INFO:Configured maximal token sequence length: max_len = 110\n",
      "05:22:32 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/agreeable-hog-157/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/agreeable-hog-157/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/agreeable-hog-157/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/agreeable-hog-157/0_data_test.csv')]\n",
      "05:22:32 INFO:Starting iteration=0\n",
      "2023-08-02 17:22:32.193511: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-08-02 17:22:32.193895: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-08-02 17:22:32.193899: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-08-02 17:22:32.195054: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-02 17:22:32.195083: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-08-02 17:22:48.360216: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-02 17:22:48.481215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-02 17:22:48.493566: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/34 [=>............................] - ETA: 1s "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 17:22:48.568168: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-02 17:22:48.579773: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 2s 28ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434ac85126054794846cdc5b18467b75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-02 17:22:56.491227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-02 17:22:56.607792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-02 17:22:56.620852: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-02 17:22:56.677532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-02 17:22:56.689241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 33ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fee5e0af1f4454dbfd3ada0df623348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:23:27 INFO:Logged iteration result res.precision=0.6785197993750054 res.recall=0.6210453403735732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3877289593219757, 'eval_step': 0, 'eval_precision': 0.6785197993750054, 'eval_recall': 0.6210453403735732, 'eval_label_count': 10, 'eval_runtime': 2.1799, 'eval_samples_per_second': 123.401, 'eval_steps_per_second': 4.129, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:23:55 INFO:Logged iteration result res.precision=0.7109153347379487 res.recall=0.6501353831975434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3604417145252228, 'eval_step': 2, 'eval_precision': 0.7109153347379487, 'eval_recall': 0.6501353831975434, 'eval_label_count': 10, 'eval_runtime': 2.1227, 'eval_samples_per_second': 126.728, 'eval_steps_per_second': 4.24, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:24:24 INFO:Logged iteration result res.precision=0.7242304606491978 res.recall=0.6624658589748673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3427518308162689, 'eval_step': 4, 'eval_precision': 0.7242304606491978, 'eval_recall': 0.6624658589748673, 'eval_label_count': 10, 'eval_runtime': 2.1128, 'eval_samples_per_second': 127.317, 'eval_steps_per_second': 4.26, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:24:53 INFO:Logged iteration result res.precision=0.7104402268850564 res.recall=0.6524016684226558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3502000570297241, 'eval_step': 6, 'eval_precision': 0.7104402268850564, 'eval_recall': 0.6524016684226558, 'eval_label_count': 10, 'eval_runtime': 2.0813, 'eval_samples_per_second': 129.244, 'eval_steps_per_second': 4.324, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:25:22 INFO:Logged iteration result res.precision=0.7033692947095227 res.recall=0.639471981999616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35459452867507935, 'eval_step': 8, 'eval_precision': 0.7033692947095227, 'eval_recall': 0.639471981999616, 'eval_label_count': 10, 'eval_runtime': 2.0613, 'eval_samples_per_second': 130.497, 'eval_steps_per_second': 4.366, 'epoch': 5.0}\n",
      "{'train_runtime': 146.5491, 'train_samples_per_second': 36.677, 'train_steps_per_second': 1.16, 'train_loss': 0.3198078155517578, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:25:28 INFO:Logged iteration result res.precision=0.7242304606491978 res.recall=0.6624658589748673\n",
      "05:25:28 INFO:Logged iteration result res.precision=0.7242304606491978 res.recall=0.6624658589748673\n",
      "05:25:28 INFO:Finished iteration=0\n",
      "05:25:28 INFO:Logging model artifact (might take a while)\n",
      "05:27:04 INFO:Breaking early after iteration=0 of 5 folds\n",
      "05:27:05 INFO:Logged experiment result res.mean_precision=0.7242304606491978 res.mean_recall=0.6624658589748673\n",
      "05:27:06 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a365d209241245779cdb960b02ad8cee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_bilstm')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_bilstm_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_bilstm_experiment_config.name = \"Production: BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_bilstm_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_bilstm_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_bilstm_config,\n",
    "        experiment=bert_2_bilstm_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_bilstm=bilstm_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_bilstm_cfg))\n",
    "\n",
    "bert_2_bilstm_run_id = get_run_id(bert_2_bilstm_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_bilstm_run_id)\n",
    "\n",
    "bert_2_bilstm_run = mlflow.get_run(bert_2_bilstm_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_bilstm_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_bilstm\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\n",
    "    \"./src/service/models/bert_2_bilstm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT E2E Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:27:23 INFO:\n",
      "bert:\n",
      "  model: bert-base-cased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "experiment:\n",
      "  name: 'Production: BERT Train for E2E Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "2023/08/02 17:27:23 INFO mlflow.tracking.fluent: Experiment with name 'Production: BERT Train for E2E Application' does not exist. Creating a new experiment.\n",
      "05:27:24 INFO:New experiment. Running\n",
      "05:27:24 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:27:24 INFO:Using device: mps\n",
      "05:27:24 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "05:27:24 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "05:27:24 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "05:27:27 INFO:Dataset Labels: transformed_dataset['labels']=['0', 'System_Level', 'Domain_Data', 'System_Function', 'Workspace', 'Stakeholder', 'Task', 'Interaction_Data', 'Interaction', 'Activity']\n",
      "05:27:27 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "05:27:27 INFO:Configured maximal token sequence length: max_len = 110\n",
      "05:27:29 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/whimsical-fawn-457/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/whimsical-fawn-457/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/whimsical-fawn-457/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/whimsical-fawn-457/0_data_test.csv')]\n",
      "05:27:29 INFO:Starting iteration=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd2e84ce59b4da6994ae5095a73bae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2839b53203fe44d8841ea1624ee39a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:27:57 INFO:Logged iteration result res.precision=0.6754306099924179 res.recall=0.6122681073757391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38905689120292664, 'eval_step': 0, 'eval_precision': 0.6754306099924179, 'eval_recall': 0.6122681073757391, 'eval_label_count': 10, 'eval_runtime': 2.2189, 'eval_samples_per_second': 121.232, 'eval_steps_per_second': 4.056, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:28:26 INFO:Logged iteration result res.precision=0.6966832510251301 res.recall=0.6467484214246293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35911062359809875, 'eval_step': 2, 'eval_precision': 0.6966832510251301, 'eval_recall': 0.6467484214246293, 'eval_label_count': 10, 'eval_runtime': 2.0951, 'eval_samples_per_second': 128.393, 'eval_steps_per_second': 4.296, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:28:55 INFO:Logged iteration result res.precision=0.7117798220201934 res.recall=0.6560636405448642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3427491784095764, 'eval_step': 4, 'eval_precision': 0.7117798220201934, 'eval_recall': 0.6560636405448642, 'eval_label_count': 10, 'eval_runtime': 2.0786, 'eval_samples_per_second': 129.412, 'eval_steps_per_second': 4.33, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:29:24 INFO:Logged iteration result res.precision=0.7091561872296284 res.recall=0.6542446017238897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3509758710861206, 'eval_step': 6, 'eval_precision': 0.7091561872296284, 'eval_recall': 0.6542446017238897, 'eval_label_count': 10, 'eval_runtime': 2.0765, 'eval_samples_per_second': 129.548, 'eval_steps_per_second': 4.334, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:29:52 INFO:Logged iteration result res.precision=0.6971341553968405 res.recall=0.6398233761687562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35496285557746887, 'eval_step': 8, 'eval_precision': 0.6971341553968405, 'eval_recall': 0.6398233761687562, 'eval_label_count': 10, 'eval_runtime': 2.0875, 'eval_samples_per_second': 128.863, 'eval_steps_per_second': 4.311, 'epoch': 5.0}\n",
      "{'train_runtime': 145.2095, 'train_samples_per_second': 37.015, 'train_steps_per_second': 1.171, 'train_loss': 0.3215824800379136, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05:29:58 INFO:Logged iteration result res.precision=0.7117798220201934 res.recall=0.6560636405448642\n",
      "05:29:58 INFO:Logged iteration result res.precision=0.7117798220201934 res.recall=0.6560636405448642\n",
      "05:29:58 INFO:Finished iteration=0\n",
      "05:29:58 INFO:Logging model artifact (might take a while)\n",
      "05:31:35 INFO:Breaking early after iteration=0 of 5 folds\n",
      "05:31:36 INFO:Logged experiment result res.mean_precision=0.7117798220201934 res.mean_recall=0.6560636405448642\n",
      "05:31:36 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e77fb13ae0e647878961516031b007a2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BERTConfig, BERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_experiment_config.name = \"Production: BERT Train for E2E Application\"\n",
    "\n",
    "bert_config = BERT(max_len=sentence_length)\n",
    "\n",
    "bert_cfg = OmegaConf.structured(\n",
    "    BERTConfig(\n",
    "        bert=bert_config,\n",
    "        experiment=bert_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bert import bert\n",
    "    bert(OmegaConf.create(bert_cfg))\n",
    "\n",
    "bert_run_id = get_run_id(bert_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_run_id)\n",
    "\n",
    "run = mlflow.get_run(bert_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{run.info.artifact_uri}/0_model\", dst_path=Path(\"./src/service/models/\")\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
