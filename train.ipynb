{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import shutil\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.config_store import ConfigStore\n",
    "import mlflow\n",
    "from src.experiments.sner import sner\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s:%(message)s\",\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%I:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_experiments=True\n",
      "pin_commits=True\n"
     ]
    }
   ],
   "source": [
    "sentence_length = 110\n",
    "\n",
    "run_experiments = os.getenv(\"UVL_BERT_RUN_EXPERIMENTS\",\"True\") == \"True\"\n",
    "pin_commits = os.getenv(\"UVL_BERT_PIN_COMMITS\",\"True\") == \"True\"\n",
    "\n",
    "print(f\"{run_experiments=}\")\n",
    "print(f\"{pin_commits=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tooling.config import Experiment, Transformation\n",
    "\n",
    "base_experiment_config = Experiment(\n",
    "    name=\"Base Config\", iterations=1, force=False\n",
    ")\n",
    "\n",
    "levels_transformation_config = Transformation(\n",
    "    description=\"Levels\",\n",
    "    type=\"Reduced\",\n",
    "    task=\"Domain_Level\",\n",
    "    domain_data=\"Domain_Level\",\n",
    "    activity=\"Domain_Level\",\n",
    "    stakeholder=\"Domain_Level\",\n",
    "    system_function=\"Interaction_Level\",\n",
    "    interaction=\"Interaction_Level\",\n",
    "    interaction_data=\"Interaction_Level\",\n",
    "    workspace=\"Interaction_Level\",\n",
    "    software=\"System_Level\",\n",
    "    internal_action=\"System_Level\",\n",
    "    internal_data=\"System_Level\",\n",
    ")\n",
    "\n",
    "label_transformation_config = Transformation(\n",
    "    description=\"None\",\n",
    "    type=\"Full\",\n",
    "    task=\"Task\",\n",
    "    domain_data=\"Domain_Data\",\n",
    "    activity=\"Activity\",\n",
    "    stakeholder=\"Stakeholder\",\n",
    "    system_function=\"System_Function\",\n",
    "    interaction=\"Interaction\",\n",
    "    interaction_data=\"Interaction_Data\",\n",
    "    workspace=\"Workspace\",\n",
    "    software=\"System_Level\",\n",
    "    internal_action=\"System_Level\",\n",
    "    internal_data=\"System_Level\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:41:49 INFO:Hint Label2Id: hint_label2id={'0': 0, 'Domain_Level': 1, 'Interaction_Level': 2, 'System_Level': 3}\n",
      "02:41:49 INFO:Hint Label2Id: hint_label2id={'0': 0, 'Task': 1, 'Domain_Data': 2, 'Activity': 3, 'Stakeholder': 4, 'System_Function': 5, 'Interaction': 6, 'Interaction_Data': 7, 'Workspace': 8, 'System_Level': 9}\n"
     ]
    }
   ],
   "source": [
    "from tooling.transformation import get_hint_transformation\n",
    "import pickle\n",
    "\n",
    "hint_transformation = get_hint_transformation(\n",
    "    transformation_cfg=OmegaConf.structured(levels_transformation_config)\n",
    ")\n",
    "hint_label2id = hint_transformation[\"label2id\"]\n",
    "pickle.dump(\n",
    "    hint_label2id, open(\"./src/service/models/hint_label2id.pickle\", \"wb\")\n",
    ")\n",
    "hint_id2label = {y: x for x, y in hint_label2id.items()}\n",
    "pickle.dump(\n",
    "    hint_id2label, open(\"./src/service/models/hint_id2label.pickle\", \"wb\")\n",
    ")\n",
    "\n",
    "transformation = get_hint_transformation(\n",
    "    transformation_cfg=OmegaConf.structured(label_transformation_config)\n",
    ")\n",
    "label2id = transformation[\"label2id\"]\n",
    "pickle.dump(label2id, open(\"./src/service/models/label2id.pickle\", \"wb\"))\n",
    "id2label = {y: x for x, y in label2id.items()}\n",
    "pickle.dump(id2label, open(\"./src/service/models/id2label.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BiLSTM First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:41:52 INFO:\n",
      "bilstm:\n",
      "  type: BiLSTM\n",
      "  sentence_length: 110\n",
      "  batch_size: 32\n",
      "  number_epochs: 4\n",
      "  verbose: 1\n",
      "  weighted_classes: false\n",
      "  learning_rate: 0.0001\n",
      "experiment:\n",
      "  name: 'Production: BiLSTM Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: true\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Domain_Level\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "02:41:52 INFO:New experiment. Running\n",
      "02:41:52 INFO:Entering mlflow context\n",
      "02:41:53 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "02:41:53 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "02:41:53 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "02:41:56 INFO:Dataset Labels: transformed_dataset['labels']=['System_Level', 'Interaction_Level', 'Domain_Level', '0']\n",
      "02:41:56 INFO:Configured maximal sentence length: sentence_length = 110\n",
      "02:41:56 INFO:Class weights: {'0': 1.0, 'Domain_Level': 1.0, 'Interaction_Level': 1.0, 'System_Level': 1.0}\n",
      "02:41:56 INFO:loading projection weights from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz\n",
      "02:42:36 INFO:KeyedVectors lifecycle event {'msg': 'loaded (1193514, 100) matrix of type float32 from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-08-15T14:42:36.193245', 'gensim': '4.3.1', 'python': '3.11.4 (main, Jun 20 2023, 19:14:10) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n",
      "02:42:38 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/dazzling-snipe-142/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/dazzling-snipe-142/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/dazzling-snipe-142/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/dazzling-snipe-142/0_data_test.csv')]\n",
      "02:42:38 INFO:Starting iteration=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "34/34 [==============================] - 6s 180ms/step - loss: 1.2503 - precision: 0.3333 - recall: 0.3563 - val_loss: 1.1118 - val_precision: 0.3172 - val_recall: 0.3333\n",
      "Epoch 2/4\n",
      "34/34 [==============================] - 6s 177ms/step - loss: 0.8755 - precision: 0.3172 - recall: 0.3333 - val_loss: 0.3759 - val_precision: 0.3172 - val_recall: 0.3333\n",
      "Epoch 3/4\n",
      "34/34 [==============================] - 6s 173ms/step - loss: 0.2107 - precision: 0.3172 - recall: 0.3333 - val_loss: 0.1725 - val_precision: 0.3172 - val_recall: 0.3333\n",
      "Epoch 4/4\n",
      "34/34 [==============================] - 6s 180ms/step - loss: 0.1635 - precision: 0.3172 - recall: 0.3333 - val_loss: 0.1553 - val_precision: 0.3172 - val_recall: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:43:10 INFO:Assets written to: /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/bilstm/dazzling-snipe-142/0_model/assets\n",
      "2023-08-15 14:43:19.442699: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 14:43:19.558348: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 14:43:19.571388: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 14:43:19.623863: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 14:43:19.635237: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 35ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "02:43:20 INFO:Logged iteration result res.precision=0.18282600526118 res.recall=0.25\n",
      "02:43:20 INFO:Finished iteration=0\n",
      "02:43:20 INFO:Breaking early after iteration=0 of 5 folds\n",
      "02:43:21 INFO:Logged experiment result res.mean_precision=0.18282600526118 res.mean_recall=0.25\n",
      "02:43:21 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b97f80571648461688b5399a230d499a\n",
      "mlflow-artifacts:/32/0ab4fdfb4c2b482ca797b592b6c9da01/artifacts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bilstm')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BiLSTMConfig, BiLSTM\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bilstm_experiment_config = deepcopy(base_experiment_config)\n",
    "bilstm_experiment_config.name = \"Production: BiLSTM Train for Staged Application\"\n",
    "\n",
    "bilstm_config = BiLSTM(sentence_length=sentence_length)\n",
    "\n",
    "bilstm_cfg: BiLSTMConfig = OmegaConf.structured(\n",
    "    BiLSTMConfig(\n",
    "        bilstm=bilstm_config,\n",
    "        experiment=bilstm_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "#bilstm_cfg.experiment.force = True\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bilstm import bilstm\n",
    "    bilstm(bilstm_cfg)\n",
    "\n",
    "\n",
    "bilstm_run_id = get_run_id(bilstm_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bilstm_run_id)\n",
    "\n",
    "print(mlflow.get_artifact_uri())\n",
    "\n",
    "bilstm_run = mlflow.get_run(bilstm_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bilstm_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bilstm\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bilstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SNER First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:53:16 INFO:\n",
      "sner:\n",
      "  type: SNER\n",
      "experiment:\n",
      "  name: 'Production: SNER Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Domain_Level\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "11:53:16 WARNING:Experiment was already run, aborting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow-artifacts:/32/55df6bc6c58548069fd69f6146d4db82/artifacts\n",
      "9b40a85a79a34363866cde507f5ea4f8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/sner.ser.gz')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import SNERConfig, SNER\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "sner_experiment_config = deepcopy(base_experiment_config)\n",
    "sner_experiment_config.name = \"Production: SNER Train for Staged Application\"\n",
    "\n",
    "sner_config = SNER()\n",
    "\n",
    "sner_cfg = OmegaConf.structured(\n",
    "    SNERConfig(\n",
    "        sner=sner_config,\n",
    "        experiment=sner_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.sner import sner\n",
    "    sner(OmegaConf.create(sner_cfg))\n",
    "\n",
    "sner_run_id = get_run_id(sner_cfg, pin_commit = pin_commits)\n",
    "print(mlflow.get_artifact_uri())\n",
    "print(sner_run_id)\n",
    "\n",
    "sner_run = mlflow.get_run(sner_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{sner_run.info.artifact_uri}/0_model.ser.gz\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    Path(\"./src/service/models/sner.ser.gz\").unlink()\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model.ser.gz\").rename(\n",
    "    \"./src/service/models/sner.ser.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:53:18 INFO:Created a temporary directory at /var/folders/82/x_tg3xgx1px781gb8v4bny1r0000gn/T/tmp42bfdsdz\n",
      "11:53:18 INFO:Writing /var/folders/82/x_tg3xgx1px781gb8v4bny1r0000gn/T/tmp42bfdsdz/_remote_module_non_scriptable.py\n",
      "11:53:18 INFO:\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "experiment:\n",
      "  name: 'Production: BERT_1 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Domain_Level\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "11:53:18 WARNING:Experiment was already run, aborting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ad9ba334cb04a70a3129e6309d2be0a\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BERTConfig, BERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_1_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_1_experiment_config.name = \"Production: BERT_1 Train for Staged Application\"\n",
    "\n",
    "bert_1_config = BERT(max_len=sentence_length)\n",
    "\n",
    "bert_1_cfg = OmegaConf.structured(\n",
    "    BERTConfig(\n",
    "        bert=bert_1_config,\n",
    "        experiment=bert_1_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bert import bert\n",
    "    bert(OmegaConf.create(bert_1_cfg))\n",
    "\n",
    "bert_1_run_id = get_run_id(bert_1_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_1_run_id)\n",
    "\n",
    "bert_1_run = mlflow.get_run(bert_1_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_1_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_1\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for BERT First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:53:38 INFO:\n",
      "first_model_bert:\n",
      "  bert:\n",
      "    model: bert-base-uncased\n",
      "    type: BERT\n",
      "    max_len: 110\n",
      "    train_batch_size: 32\n",
      "    validation_batch_size: 32\n",
      "    number_epochs: 5\n",
      "    learning_rate_bert: 2.0e-05\n",
      "    learning_rate_classifier: 0.01\n",
      "    weight_decay: 0.01\n",
      "    weighted_classes: false\n",
      "  experiment:\n",
      "    name: 'Production: BERT_1 Train for Staged Application'\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Domain_Level\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "first_model_bilstm: null\n",
      "first_model_sner: null\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: 'Production: BERT_2 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: true\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "\n",
      "11:53:38 INFO:New experiment. Running\n",
      "11:53:38 INFO:Entering mlflow context\n",
      "11:53:39 INFO:Using device: mps\n",
      "11:53:40 INFO:Found existing run with run_id: 2ad9ba334cb04a70a3129e6309d2be0a matching the configuration\n",
      "11:53:40 INFO:Downloading run model from mlflow-artifacts:/34/2ad9ba334cb04a70a3129e6309d2be0a/artifacts/0_model\n",
      "11:54:04 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "11:54:04 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "11:54:04 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "11:54:07 INFO:Dataset Labels: transformed_dataset['labels']=['Activity', 'System_Level', '0', 'Stakeholder', 'Interaction_Data', 'Task', 'Domain_Data', 'System_Function', 'Interaction', 'Workspace']\n",
      "11:54:07 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "11:54:07 INFO:Configured maximal token sequence length: max_len = 110\n",
      "11:54:08 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-sloth-591/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-sloth-591/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-sloth-591/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-sloth-591/0_data_test.csv')]\n",
      "11:54:08 INFO:Starting iteration=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740cdf51b9f741938a7cdaf2ae4ca152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:54:09 INFO:Loading Model\n",
      "11:54:09 INFO:Using device: mps\n",
      "11:54:10 INFO:Creating hint column\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9633c77234d04c699ac3b6630126726f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4e8401579c49fb8bea202e56b40fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:54:44 INFO:Loading Model\n",
      "11:54:45 INFO:Using device: mps\n",
      "11:54:45 INFO:Creating hint column\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1cfed5332914ed1ae724143e6b2ba06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:55:24 INFO:Logged iteration result res.precision=0.6644742640495378 res.recall=0.634449273041086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3852716386318207, 'eval_step': 0, 'eval_precision': 0.6644742640495378, 'eval_recall': 0.634449273041086, 'eval_label_count': 10, 'eval_runtime': 2.35, 'eval_samples_per_second': 114.467, 'eval_steps_per_second': 3.83, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:55:54 INFO:Logged iteration result res.precision=0.683063245359526 res.recall=0.6392365560858139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36605221033096313, 'eval_step': 2, 'eval_precision': 0.683063245359526, 'eval_recall': 0.6392365560858139, 'eval_label_count': 10, 'eval_runtime': 2.2585, 'eval_samples_per_second': 119.104, 'eval_steps_per_second': 3.985, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:56:24 INFO:Logged iteration result res.precision=0.7264684253132685 res.recall=0.6805139460710684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34947481751441956, 'eval_step': 4, 'eval_precision': 0.7264684253132685, 'eval_recall': 0.6805139460710684, 'eval_label_count': 10, 'eval_runtime': 2.2827, 'eval_samples_per_second': 117.842, 'eval_steps_per_second': 3.943, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:56:54 INFO:Logged iteration result res.precision=0.7013307297670722 res.recall=0.6533171622014382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3614483177661896, 'eval_step': 6, 'eval_precision': 0.7013307297670722, 'eval_recall': 0.6533171622014382, 'eval_label_count': 10, 'eval_runtime': 2.1454, 'eval_samples_per_second': 125.386, 'eval_steps_per_second': 4.195, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:57:24 INFO:Logged iteration result res.precision=0.703754153738194 res.recall=0.6551194365013446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.360973060131073, 'eval_step': 8, 'eval_precision': 0.703754153738194, 'eval_recall': 0.6551194365013446, 'eval_label_count': 10, 'eval_runtime': 2.3081, 'eval_samples_per_second': 116.546, 'eval_steps_per_second': 3.899, 'epoch': 5.0}\n",
      "{'train_runtime': 152.3414, 'train_samples_per_second': 35.283, 'train_steps_per_second': 1.116, 'train_loss': 0.312238670797909, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:57:30 INFO:Logged iteration result res.precision=0.7264684253132685 res.recall=0.6805139460710684\n",
      "11:57:30 INFO:Logged iteration result res.precision=0.7264684253132685 res.recall=0.6805139460710684\n",
      "11:57:30 INFO:Finished iteration=0\n",
      "11:57:30 INFO:Logging model artifact (might take a while)\n",
      "11:59:08 INFO:Breaking early after iteration=0 of 5 folds\n",
      "11:59:09 INFO:Logged experiment result res.mean_precision=0.7264684253132685 res.mean_recall=0.6805139460710684\n",
      "11:59:09 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "a574cd93fe0b456dadaaac30e56e0aa5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_bert')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_bert_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_bert_experiment_config.name = \"Production: BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_bert_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_bert_cfg: DualModelStagedBERTConfig = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_bert_config,\n",
    "        experiment=bert_2_bert_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_bert=bert_1_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_bert_cfg))\n",
    "\n",
    "bert_2_bert_run_id = get_run_id(bert_2_bert_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_bert_run_id)\n",
    "\n",
    "bert_2_bert_run = mlflow.get_run(bert_2_bert_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_bert_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_bert\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_2_bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for SNER First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:28 INFO:\n",
      "first_model_bert: null\n",
      "first_model_bilstm: null\n",
      "first_model_sner:\n",
      "  sner:\n",
      "    type: SNER\n",
      "  experiment:\n",
      "    name: 'Production: SNER Train for Staged Application'\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Domain_Level\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: 'Production: BERT_2 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "\n",
      "11:59:29 INFO:New experiment. Running\n",
      "11:59:29 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:29 INFO:Using device: mps\n",
      "11:59:30 INFO:Found existing run with run_id: 9b40a85a79a34363866cde507f5ea4f8 matching the configuration\n",
      "11:59:30 INFO:Downloading run model from mlflow-artifacts:/33/9b40a85a79a34363866cde507f5ea4f8/artifacts/0_model.ser.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:59:30 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "11:59:31 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "11:59:31 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "11:59:33 INFO:Dataset Labels: transformed_dataset['labels']=['Activity', 'System_Level', '0', 'Stakeholder', 'Interaction_Data', 'Task', 'Domain_Data', 'System_Function', 'Interaction', 'Workspace']\n",
      "11:59:33 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "11:59:33 INFO:Configured maximal token sequence length: max_len = 110\n",
      "11:59:34 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/debonair-donkey-398/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/debonair-donkey-398/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/debonair-donkey-398/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/debonair-donkey-398/0_data_test.csv')]\n",
      "11:59:34 INFO:Starting iteration=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f82801ffc6d4f068563b796ced98fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "274ea949f5fe41549fd0cfdf0147a7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:00:07 INFO:Logged iteration result res.precision=0.6754658112454573 res.recall=0.6221767408632006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3807903528213501, 'eval_step': 0, 'eval_precision': 0.6754658112454573, 'eval_recall': 0.6221767408632006, 'eval_label_count': 10, 'eval_runtime': 2.2948, 'eval_samples_per_second': 117.224, 'eval_steps_per_second': 3.922, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:00:37 INFO:Logged iteration result res.precision=0.7055229565096252 res.recall=0.6291483757238951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35418346524238586, 'eval_step': 2, 'eval_precision': 0.7055229565096252, 'eval_recall': 0.6291483757238951, 'eval_label_count': 10, 'eval_runtime': 2.2835, 'eval_samples_per_second': 117.804, 'eval_steps_per_second': 3.941, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:01:07 INFO:Logged iteration result res.precision=0.7207249044272385 res.recall=0.6588470895526491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34985023736953735, 'eval_step': 4, 'eval_precision': 0.7207249044272385, 'eval_recall': 0.6588470895526491, 'eval_label_count': 10, 'eval_runtime': 2.2126, 'eval_samples_per_second': 121.575, 'eval_steps_per_second': 4.068, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:01:37 INFO:Logged iteration result res.precision=0.6785854207731388 res.recall=0.625104590134425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3637900948524475, 'eval_step': 6, 'eval_precision': 0.6785854207731388, 'eval_recall': 0.625104590134425, 'eval_label_count': 10, 'eval_runtime': 2.1623, 'eval_samples_per_second': 124.406, 'eval_steps_per_second': 4.162, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:02:06 INFO:Logged iteration result res.precision=0.6876090337775963 res.recall=0.632028136051705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36508819460868835, 'eval_step': 8, 'eval_precision': 0.6876090337775963, 'eval_recall': 0.632028136051705, 'eval_label_count': 10, 'eval_runtime': 2.2024, 'eval_samples_per_second': 122.139, 'eval_steps_per_second': 4.086, 'epoch': 5.0}\n",
      "{'train_runtime': 149.9144, 'train_samples_per_second': 35.854, 'train_steps_per_second': 1.134, 'train_loss': 0.24499363618738512, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:02:12 INFO:Logged iteration result res.precision=0.7207249044272385 res.recall=0.6588470895526491\n",
      "12:02:12 INFO:Logged iteration result res.precision=0.7207249044272385 res.recall=0.6588470895526491\n",
      "12:02:12 INFO:Finished iteration=0\n",
      "12:02:12 INFO:Logging model artifact (might take a while)\n",
      "12:03:49 INFO:Breaking early after iteration=0 of 5 folds\n",
      "12:03:50 INFO:Logged experiment result res.mean_precision=0.7207249044272385 res.mean_recall=0.6588470895526491\n",
      "12:03:50 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "3385dbbaafaf4c589f0a7868a59d24ee\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_sner')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_sner_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_sner_experiment_config.name = \"Production: BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_sner_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_sner_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_sner_config,\n",
    "        experiment=bert_2_sner_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_sner=sner_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_sner_cfg))\n",
    "\n",
    "bert_2_sner_run_id = get_run_id(bert_2_sner_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_sner_run_id)\n",
    "\n",
    "bert_2_sner_run = mlflow.get_run(bert_2_sner_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_sner_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_sner\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_2_sner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for BILSTM First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:04:09 INFO:\n",
      "first_model_bert: null\n",
      "first_model_bilstm:\n",
      "  bilstm:\n",
      "    type: BiLSTM\n",
      "    sentence_length: 110\n",
      "    batch_size: 32\n",
      "    number_epochs: 32\n",
      "    verbose: 1\n",
      "    weighted_classes: false\n",
      "    learning_rate: 0.0001\n",
      "  experiment:\n",
      "    name: 'Production: BiLSTM Train for Staged Application'\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Domain_Level\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "first_model_sner: null\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: 'Production: BERT_2 Train for Staged Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "\n",
      "12:04:09 INFO:New experiment. Running\n",
      "12:04:09 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:04:09 INFO:Using device: mps\n",
      "12:04:10 INFO:Found existing run with run_id: 699064dbd3854a86a6e0f106e153739e matching the configuration\n",
      "12:04:10 INFO:Downloading run model from mlflow-artifacts:/32/699064dbd3854a86a6e0f106e153739e/artifacts/0_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:04:12 INFO:loading projection weights from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz\n",
      "12:04:47 INFO:KeyedVectors lifecycle event {'msg': 'loaded (1193514, 100) matrix of type float32 from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-08-15T12:04:47.320114', 'gensim': '4.3.1', 'python': '3.11.4 (main, Jun 20 2023, 19:14:10) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n",
      "12:04:47 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "12:04:47 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "12:04:48 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "12:04:50 INFO:Dataset Labels: transformed_dataset['labels']=['Activity', 'System_Level', '0', 'Stakeholder', 'Interaction_Data', 'Task', 'Domain_Data', 'System_Function', 'Interaction', 'Workspace']\n",
      "12:04:51 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "12:04:51 INFO:Configured maximal token sequence length: max_len = 110\n",
      "12:04:52 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-skunk-777/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-skunk-777/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-skunk-777/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/abrasive-skunk-777/0_data_test.csv')]\n",
      "12:04:52 INFO:Starting iteration=0\n",
      "2023-08-15 12:04:52.902378: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-08-15 12:04:52.902435: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-08-15 12:04:52.902438: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-08-15 12:04:52.902466: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-15 12:04:52.902508: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2023-08-15 12:05:09.521223: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 12:05:09.641452: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 12:05:09.653812: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 12:05:09.718717: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/34 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 12:05:09.734213: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 2s 27ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14578f79cb214a239ef81d43d41c2685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 12:05:17.545088: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 12:05:17.660722: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 12:05:17.673897: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 12:05:17.724029: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-15 12:05:17.735742: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 35ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bba7dba449145abaf19cb974e2da901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:05:49 INFO:Logged iteration result res.precision=0.6682133460512885 res.recall=0.6197093034337275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3860763609409332, 'eval_step': 0, 'eval_precision': 0.6682133460512885, 'eval_recall': 0.6197093034337275, 'eval_label_count': 10, 'eval_runtime': 2.2767, 'eval_samples_per_second': 118.154, 'eval_steps_per_second': 3.953, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:19 INFO:Logged iteration result res.precision=0.694983442358099 res.recall=0.641296833154226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36157548427581787, 'eval_step': 2, 'eval_precision': 0.694983442358099, 'eval_recall': 0.641296833154226, 'eval_label_count': 10, 'eval_runtime': 2.2054, 'eval_samples_per_second': 121.974, 'eval_steps_per_second': 4.081, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:49 INFO:Logged iteration result res.precision=0.7211404156400778 res.recall=0.6836553227628458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3480065166950226, 'eval_step': 4, 'eval_precision': 0.7211404156400778, 'eval_recall': 0.6836553227628458, 'eval_label_count': 10, 'eval_runtime': 2.2325, 'eval_samples_per_second': 120.494, 'eval_steps_per_second': 4.031, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:07:19 INFO:Logged iteration result res.precision=0.6948940883172359 res.recall=0.6539314679890676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35891425609588623, 'eval_step': 6, 'eval_precision': 0.6948940883172359, 'eval_recall': 0.6539314679890676, 'eval_label_count': 10, 'eval_runtime': 2.3591, 'eval_samples_per_second': 114.029, 'eval_steps_per_second': 3.815, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:07:50 INFO:Logged iteration result res.precision=0.7020240090507268 res.recall=0.6558736978600617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35905617475509644, 'eval_step': 8, 'eval_precision': 0.7020240090507268, 'eval_recall': 0.6558736978600617, 'eval_label_count': 10, 'eval_runtime': 2.2789, 'eval_samples_per_second': 118.04, 'eval_steps_per_second': 3.949, 'epoch': 5.0}\n",
      "{'train_runtime': 152.9563, 'train_samples_per_second': 35.141, 'train_steps_per_second': 1.111, 'train_loss': 0.31347095265107994, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:07:55 INFO:Logged iteration result res.precision=0.7211404156400778 res.recall=0.6836553227628458\n",
      "12:07:56 INFO:Logged iteration result res.precision=0.7211404156400778 res.recall=0.6836553227628458\n",
      "12:07:56 INFO:Finished iteration=0\n",
      "12:07:56 INFO:Logging model artifact (might take a while)\n",
      "12:09:34 INFO:Breaking early after iteration=0 of 5 folds\n",
      "12:09:35 INFO:Logged experiment result res.mean_precision=0.7211404156400778 res.mean_recall=0.6836553227628458\n",
      "12:09:35 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "d54d1caaff404a2b8cbbfa9c479dabad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_bilstm')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_bilstm_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_bilstm_experiment_config.name = \"Production: BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_bilstm_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_bilstm_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_bilstm_config,\n",
    "        experiment=bert_2_bilstm_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_bilstm=bilstm_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_bilstm_cfg))\n",
    "\n",
    "bert_2_bilstm_run_id = get_run_id(bert_2_bilstm_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_bilstm_run_id)\n",
    "\n",
    "bert_2_bilstm_run = mlflow.get_run(bert_2_bilstm_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_bilstm_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_bilstm\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\n",
    "    \"./src/service/models/bert_2_bilstm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT E2E Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:09:54 INFO:\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "experiment:\n",
      "  name: 'Production: BERT Train for E2E Application'\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "\n",
      "12:09:55 INFO:New experiment. Running\n",
      "12:09:55 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:09:55 INFO:Using device: mps\n",
      "12:09:55 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "12:09:55 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "12:09:56 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "12:09:58 INFO:Dataset Labels: transformed_dataset['labels']=['Activity', 'System_Level', '0', 'Stakeholder', 'Interaction_Data', 'Task', 'Domain_Data', 'System_Function', 'Interaction', 'Workspace']\n",
      "12:09:58 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "12:09:58 INFO:Configured maximal token sequence length: max_len = 110\n",
      "12:10:00 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/bold-wren-560/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/bold-wren-560/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/bold-wren-560/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/bold-wren-560/0_data_test.csv')]\n",
      "12:10:00 INFO:Starting iteration=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582c832a8bf645a190e49c08c4bd74d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edccb2d52ff94f44a0e590e546420f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:10:31 INFO:Logged iteration result res.precision=0.6559464277421913 res.recall=0.6235245753039973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39210978150367737, 'eval_step': 0, 'eval_precision': 0.6559464277421913, 'eval_recall': 0.6235245753039973, 'eval_label_count': 10, 'eval_runtime': 2.2577, 'eval_samples_per_second': 119.148, 'eval_steps_per_second': 3.986, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:11:01 INFO:Logged iteration result res.precision=0.6939126772464024 res.recall=0.6356914400673643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3647594749927521, 'eval_step': 2, 'eval_precision': 0.6939126772464024, 'eval_recall': 0.6356914400673643, 'eval_label_count': 10, 'eval_runtime': 2.2004, 'eval_samples_per_second': 122.253, 'eval_steps_per_second': 4.09, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:11:31 INFO:Logged iteration result res.precision=0.7178643892293535 res.recall=0.6810540380395174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.349907785654068, 'eval_step': 4, 'eval_precision': 0.7178643892293535, 'eval_recall': 0.6810540380395174, 'eval_label_count': 10, 'eval_runtime': 2.2142, 'eval_samples_per_second': 121.491, 'eval_steps_per_second': 4.065, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:12:01 INFO:Logged iteration result res.precision=0.7001814713233431 res.recall=0.653175018333902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3616948425769806, 'eval_step': 6, 'eval_precision': 0.7001814713233431, 'eval_recall': 0.653175018333902, 'eval_label_count': 10, 'eval_runtime': 2.2235, 'eval_samples_per_second': 120.981, 'eval_steps_per_second': 4.048, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:12:31 INFO:Logged iteration result res.precision=0.6987279850930139 res.recall=0.6547137195652447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3600654602050781, 'eval_step': 8, 'eval_precision': 0.6987279850930139, 'eval_recall': 0.6547137195652447, 'eval_label_count': 10, 'eval_runtime': 2.1877, 'eval_samples_per_second': 122.961, 'eval_steps_per_second': 4.114, 'epoch': 5.0}\n",
      "{'train_runtime': 151.3343, 'train_samples_per_second': 35.517, 'train_steps_per_second': 1.123, 'train_loss': 0.32144239089068244, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:12:37 INFO:Logged iteration result res.precision=0.7178643892293535 res.recall=0.6810540380395174\n",
      "12:12:37 INFO:Logged iteration result res.precision=0.7178643892293535 res.recall=0.6810540380395174\n",
      "12:12:37 INFO:Finished iteration=0\n",
      "12:12:37 INFO:Logging model artifact (might take a while)\n",
      "12:14:15 INFO:Breaking early after iteration=0 of 5 folds\n",
      "12:14:16 INFO:Logged experiment result res.mean_precision=0.7178643892293535 res.mean_recall=0.6810540380395174\n",
      "12:14:16 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "c73f5384ee3642edbb361043cbb3f646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BERTConfig, BERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_experiment_config.name = \"Production: BERT Train for E2E Application\"\n",
    "\n",
    "bert_config = BERT(max_len=sentence_length)\n",
    "\n",
    "bert_cfg = OmegaConf.structured(\n",
    "    BERTConfig(\n",
    "        bert=bert_config,\n",
    "        experiment=bert_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bert import bert\n",
    "    bert(OmegaConf.create(bert_cfg))\n",
    "\n",
    "bert_run_id = get_run_id(bert_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_run_id)\n",
    "\n",
    "run = mlflow.get_run(bert_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{run.info.artifact_uri}/0_model\", dst_path=Path(\"./src/service/models/\")\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
