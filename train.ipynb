{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import shutil\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.config_store import ConfigStore\n",
    "import mlflow\n",
    "from src.experiments.sner import sner\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s:%(message)s\",\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%I:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_experiments='True'\n",
      "pin_commits=False\n"
     ]
    }
   ],
   "source": [
    "sentence_length = 106\n",
    "\n",
    "run_experiments = os.getenv(\"UVL_BERT_RUN_EXPERIMENTS\", \"True\")\n",
    "pin_commits = os.getenv(\"UVL_BERT_PIN_COMMITS\", \"True\") == \"FALSE\"\n",
    "\n",
    "print(f\"{run_experiments=}\")\n",
    "print(f\"{pin_commits=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tooling.config import Experiment, Transformation\n",
    "\n",
    "base_experiment_config = Experiment(\n",
    "    name=\"Base Config\", iterations=1, force=False, dataset=\"all\"\n",
    ")\n",
    "\n",
    "levels_transformation_config = Transformation(\n",
    "    description=\"Levels\",\n",
    "    type=\"Reduced\",\n",
    "    task=\"Domain_Level\",\n",
    "    domain_data=\"Domain_Level\",\n",
    "    activity=\"Domain_Level\",\n",
    "    stakeholder=\"Domain_Level\",\n",
    "    system_function=\"Interaction_Level\",\n",
    "    interaction=\"Interaction_Level\",\n",
    "    interaction_data=\"Interaction_Level\",\n",
    "    workspace=\"Interaction_Level\",\n",
    "    software=\"System_Level\",\n",
    "    internal_action=\"System_Level\",\n",
    "    internal_data=\"System_Level\",\n",
    ")\n",
    "\n",
    "label_transformation_config = Transformation(\n",
    "    description=\"None\",\n",
    "    type=\"Full\",\n",
    "    task=\"Task\",\n",
    "    domain_data=\"Domain_Data\",\n",
    "    activity=\"Activity\",\n",
    "    stakeholder=\"Stakeholder\",\n",
    "    system_function=\"System_Function\",\n",
    "    interaction=\"Interaction\",\n",
    "    interaction_data=\"Interaction_Data\",\n",
    "    workspace=\"Workspace\",\n",
    "    software=\"System_Level\",\n",
    "    internal_action=\"System_Level\",\n",
    "    internal_data=\"System_Level\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:05:39 INFO:Hint Label2Id: hint_label2id={'0': 0, 'Domain_Level': 1, 'Interaction_Level': 2, 'System_Level': 3}\n",
      "01:05:39 INFO:Hint Label2Id: hint_label2id={'0': 0, 'Task': 1, 'Domain_Data': 2, 'Activity': 3, 'Stakeholder': 4, 'System_Function': 5, 'Interaction': 6, 'Interaction_Data': 7, 'Workspace': 8, 'System_Level': 9}\n"
     ]
    }
   ],
   "source": [
    "from tooling.transformation import get_hint_transformation\n",
    "import pickle\n",
    "\n",
    "hint_transformation = get_hint_transformation(\n",
    "    transformation_cfg=OmegaConf.structured(levels_transformation_config)\n",
    ")\n",
    "hint_label2id = hint_transformation[\"label2id\"]\n",
    "pickle.dump(\n",
    "    hint_label2id, open(\"./src/service/models/hint_label2id.pickle\", \"wb\")\n",
    ")\n",
    "hint_id2label = {y: x for x, y in hint_label2id.items()}\n",
    "pickle.dump(\n",
    "    hint_id2label, open(\"./src/service/models/hint_id2label.pickle\", \"wb\")\n",
    ")\n",
    "\n",
    "transformation = get_hint_transformation(\n",
    "    transformation_cfg=OmegaConf.structured(label_transformation_config)\n",
    ")\n",
    "label2id = transformation[\"label2id\"]\n",
    "pickle.dump(label2id, open(\"./src/service/models/label2id.pickle\", \"wb\"))\n",
    "id2label = {y: x for x, y in label2id.items()}\n",
    "pickle.dump(id2label, open(\"./src/service/models/id2label.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BiLSTM First Stage Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:50:03 INFO:\n",
      "bilstm:\n",
      "  type: BiLSTM\n",
      "  sentence_length: null\n",
      "  batch_size: 32\n",
      "  number_epochs: 4\n",
      "  verbose: 1\n",
      "  weighted_classes: false\n",
      "  learning_rate: 0.0001\n",
      "experiment:\n",
      "  name: Production\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: all\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Domain_Level\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "  system_level: null\n",
      "\n",
      "07:50:04 INFO:New experiment. Running\n",
      "07:50:04 INFO:Entering mlflow context\n",
      "07:50:05 INFO:Created a temporary directory at /var/folders/82/x_tg3xgx1px781gb8v4bny1r0000gn/T/tmpcxvce8fn\n",
      "07:50:05 INFO:Writing /var/folders/82/x_tg3xgx1px781gb8v4bny1r0000gn/T/tmpcxvce8fn/_remote_module_non_scriptable.py\n",
      "07:50:06 INFO:Importing dataset: anno from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/forum/anno_test.json\n",
      "07:50:06 INFO:Importing dataset: anno from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/forum/anno_train.json\n",
      "07:50:06 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "07:50:07 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "07:50:07 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "07:50:07 INFO:Importing dataset: komoot from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/app/Komoot_AppReview.json\n",
      "07:50:11 INFO:Dataset Labels: transformed_dataset['labels']=['System_Level', 'Interaction_Level', '0', 'Domain_Level']\n",
      "07:50:11 INFO:Computed maximal sentence length: sentence_length = 106\n",
      "07:50:11 INFO:Class weights: {'0': 1.0, 'Domain_Level': 1.0, 'Interaction_Level': 1.0, 'System_Level': 1.0}\n",
      "07:50:11 INFO:loading projection weights from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz\n",
      "07:50:56 INFO:KeyedVectors lifecycle event {'msg': 'loaded (1193514, 100) matrix of type float32 from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-08-28T19:50:56.790965', 'gensim': '4.3.1', 'python': '3.11.4 (main, Jun 20 2023, 19:14:10) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n",
      "07:50:59 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/languid-boar-815/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/languid-boar-815/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/languid-boar-815/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/languid-boar-815/0_data_test.csv')]\n",
      "07:50:59 INFO:Starting iteration=0\n",
      "2023-08-28 19:50:59.952644: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
      "2023-08-28 19:50:59.952668: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2023-08-28 19:50:59.952828: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2023-08-28 19:50:59.953126: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-28 19:50:59.953154: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "78/78 [==============================] - 17s 210ms/step - loss: 0.9311 - precision: 0.3780 - recall: 0.3303 - val_loss: 0.1834 - val_precision: 0.3194 - val_recall: 0.3333\n",
      "Epoch 2/4\n",
      "78/78 [==============================] - 16s 199ms/step - loss: 0.1557 - precision: 0.3191 - recall: 0.3333 - val_loss: 0.1377 - val_precision: 0.3194 - val_recall: 0.3333\n",
      "Epoch 3/4\n",
      "78/78 [==============================] - 16s 207ms/step - loss: 0.1335 - precision: 0.4302 - recall: 0.3334 - val_loss: 0.1262 - val_precision: 0.6528 - val_recall: 0.3337\n",
      "Epoch 4/4\n",
      "78/78 [==============================] - 17s 222ms/step - loss: 0.1244 - precision: 0.5091 - recall: 0.3391 - val_loss: 0.1184 - val_precision: 0.4922 - val_recall: 0.3455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:52:15 INFO:Assets written to: /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/bilstm/languid-boar-815/0_model/assets\n",
      "2023-08-28 19:52:29.860495: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-28 19:52:30.013368: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-28 19:52:30.013399: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/20 [======>.......................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 19:52:30.221249: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-28 19:52:30.232625: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 36ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:52:31 INFO:Logged iteration result res.precision=0.31939181551676077 res.recall=0.2587330357436993\n",
      "07:52:31 INFO:Finished iteration=0\n",
      "07:52:31 INFO:Breaking early after iteration=0 of 5 folds\n",
      "07:52:32 INFO:Logged experiment result res.mean_precision=0.31939181551676077 res.mean_recall=0.2587330357436993\n",
      "07:52:33 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9cd9c07579f64068bd2cd829ee5301a7\n",
      "mlflow-artifacts:/38/d4819210a6a447b7918df5a906ba76be/artifacts\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bilstm')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BiLSTMConfig, BiLSTM\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bilstm_experiment_config = deepcopy(base_experiment_config)\n",
    "bilstm_experiment_config.name = \"Production\"\n",
    "\n",
    "bilstm_config = BiLSTM()\n",
    "\n",
    "bilstm_cfg: BiLSTMConfig = OmegaConf.structured(\n",
    "    BiLSTMConfig(\n",
    "        bilstm=bilstm_config,\n",
    "        experiment=bilstm_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "# bilstm_cfg.experiment.force = True\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bilstm import bilstm\n",
    "\n",
    "    bilstm(bilstm_cfg)\n",
    "\n",
    "\n",
    "bilstm_run_id = get_run_id(bilstm_cfg, pin_commit=pin_commits)\n",
    "\n",
    "print(bilstm_run_id)\n",
    "print(mlflow.get_artifact_uri())\n",
    "\n",
    "bilstm_run = mlflow.get_run(bilstm_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bilstm_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bilstm\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bilstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SNER First Stage Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:52:36 INFO:\n",
      "sner:\n",
      "  type: SNER\n",
      "experiment:\n",
      "  name: Production\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: all\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Domain_Level\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "  system_level: null\n",
      "\n",
      "07:52:37 INFO:New experiment. Running\n",
      "07:52:37 INFO:Entering mlflow context\n",
      "07:52:37 INFO:Importing dataset: anno from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/forum/anno_test.json\n",
      "07:52:37 INFO:Importing dataset: anno from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/forum/anno_train.json\n",
      "07:52:38 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "07:52:39 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "07:52:39 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "07:52:40 INFO:Importing dataset: komoot from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/app/Komoot_AppReview.json\n",
      "07:52:43 INFO:Dataset Labels: transformed_dataset['labels']=['System_Level', 'Interaction_Level', '0', 'Domain_Level']\n",
      "07:52:46 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/crawling-shrike-749/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/crawling-shrike-749/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/crawling-shrike-749/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/crawling-shrike-749/0_data_test.csv')]\n",
      "07:52:46 INFO:Starting iteration=0\n",
      "07:52:47 INFO:Created train file for iteration=0, stored at filepath=PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/crawling-shrike-749/0_sner_train_file.txt')\n",
      "07:52:47 INFO:Created config file for iteration=0, stored at filepath=PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/crawling-shrike-749/0_sner_config_file.prop')\n",
      "07:52:47 INFO:Starting training, only printing every 10. line.\n",
      "07:52:47 INFO:useDisjunctive=true\n",
      "\n",
      "07:52:47 INFO:useTypeSeqs=true\n",
      "\n",
      "07:52:48 INFO:numDatums: 44732\n",
      "\n",
      "07:52:49 INFO:SCALING        <D> Diagonal scaling was used; <I> Scaled Identity\n",
      "\n",
      "07:52:49 INFO:{RELNORM}      The ratio of the current to initial gradient norms\n",
      "\n",
      "07:52:50 INFO:Iter 5 evals 7 <D> [M 1,000E0] 3,085E5 1,07s |7,509E3| {1,091E-1} 2,122E-2 - \n",
      "\n",
      "07:52:52 INFO:Iter 15 evals 17 <D> [M 1,000E0] 2,668E5 2,89s |1,884E3| {2,736E-2} 1,314E-2 - \n",
      "\n",
      "07:52:54 INFO:Iter 25 evals 27 <D> [M 1,000E0] 1,076E5 4,93s |1,401E3| {2,036E-2} 1,355E-1 - \n",
      "\n",
      "07:52:56 INFO:Iter 35 evals 40 <D> [M 1,000E0] 4,061E4 7,60s |2,417E3| {3,511E-2} 1,469E-1 - \n",
      "\n",
      "07:52:59 INFO:Iter 45 evals 50 <D> [M 1,000E0] 1,906E4 9,83s |8,029E2| {1,166E-2} 9,453E-2 - \n",
      "\n",
      "07:53:01 INFO:Iter 55 evals 61 <D> [M 1,000E0] 8,941E3 12,54s |8,054E2| {1,170E-2} 9,324E-2 - \n",
      "\n",
      "07:53:04 INFO:Iter 65 evals 73 <D> [M 1,000E0] 5,852E3 15,37s |4,277E2| {6,213E-3} 4,790E-2 - \n",
      "\n",
      "07:53:07 INFO:Iter 75 evals 85 <D> [M 1,000E0] 4,456E3 18,16s |5,079E2| {7,379E-3} 2,603E-2 - \n",
      "\n",
      "07:53:10 INFO:Iter 85 evals 95 <D> [M 1,000E0] 3,953E3 20,83s |2,698E2| {3,919E-3} 1,049E-2 - \n",
      "\n",
      "07:53:12 INFO:Iter 95 evals 105 <D> [M 1,000E0] 3,764E3 23,32s |1,499E2| {2,177E-3} 4,215E-3 - \n",
      "\n",
      "07:53:15 INFO:Iter 105 evals 117 <D> [M 1,000E0] 3,708E3 26,05s |5,645E1| {8,200E-4} 1,403E-3 - \n",
      "\n",
      "07:53:18 INFO:Iter 115 evals 129 <D> [M 1,000E0] 3,687E3 28,99s |5,308E1| {7,710E-4} 4,782E-4 - \n",
      "\n",
      "07:53:21 INFO:Iter 125 evals 140 <D> [M 1,000E0] 3,677E3 31,73s |1,819E1| {2,643E-4} 2,403E-4 - \n",
      "\n",
      "07:53:23 INFO:Iter 135 evals 150 <D> [1M 1,444E-1] 3,671E3 34,38s |3,219E1| {4,676E-4} 1,254E-4 - \n",
      "\n",
      "07:53:28 INFO:Trained model for iteration=0, stored at filepath=PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/crawling-shrike-749/0_model.ser.gz')\n",
      "07:53:29 INFO:Logged classification results for iteration 0 at /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/crawling-shrike-749/0_classification_result.pickle, /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/crawling-shrike-749/0_classification_result.csv\n",
      "07:53:30 INFO:Logged solutions for iteration 0 at /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/crawling-shrike-749/0_solution.pickle, /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sner/crawling-shrike-749/0_solution.csv\n",
      "07:53:30 INFO:Logged iteration result res.precision=0.7544371433034501 res.recall=0.6881859139641906\n",
      "07:53:30 INFO:Finished iteration=0\n",
      "07:53:30 INFO:Breaking early after iteration=0 of 5 folds\n",
      "07:53:31 INFO:Logged experiment result res.mean_precision=0.7544371433034501 res.mean_recall=0.6881859139641906\n",
      "07:53:31 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow-artifacts:/38/d4819210a6a447b7918df5a906ba76be/artifacts\n",
      "1575ee955f574d47990265aa51247133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/sner.ser.gz')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import SNERConfig, SNER\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "sner_experiment_config = deepcopy(base_experiment_config)\n",
    "sner_experiment_config.name = \"Production\"\n",
    "\n",
    "sner_config = SNER()\n",
    "\n",
    "sner_cfg = OmegaConf.structured(\n",
    "    SNERConfig(\n",
    "        sner=sner_config,\n",
    "        experiment=sner_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.sner import sner\n",
    "\n",
    "    sner(OmegaConf.create(sner_cfg))\n",
    "\n",
    "sner_run_id = get_run_id(sner_cfg, pin_commit=pin_commits)\n",
    "print(mlflow.get_artifact_uri())\n",
    "print(sner_run_id)\n",
    "\n",
    "sner_run = mlflow.get_run(sner_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{sner_run.info.artifact_uri}/0_model.ser.gz\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    Path(\"./src/service/models/sner.ser.gz\").unlink()\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model.ser.gz\").rename(\n",
    "    \"./src/service/models/sner.ser.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT First Stage Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:40:22 INFO:\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 123\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "experiment:\n",
      "  name: Production\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: all\n",
      "  lower_case: false\n",
      "  force: true\n",
      "transformation:\n",
      "  description: Levels\n",
      "  type: Reduced\n",
      "  task: Domain_Level\n",
      "  goals: null\n",
      "  domain_data: Domain_Level\n",
      "  activity: Domain_Level\n",
      "  stakeholder: Domain_Level\n",
      "  system_function: Interaction_Level\n",
      "  interaction: Interaction_Level\n",
      "  interaction_data: Interaction_Level\n",
      "  workspace: Interaction_Level\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "  system_level: null\n",
      "\n",
      "10:40:22 INFO:New experiment. Running\n",
      "10:40:22 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:40:22 INFO:Using device: mps\n",
      "10:40:22 INFO:Importing dataset: anno from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/forum/anno_test.json\n",
      "10:40:23 INFO:Importing dataset: anno from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/forum/anno_train.json\n",
      "10:40:24 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "10:40:24 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "10:40:25 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "10:40:26 INFO:Importing dataset: komoot from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/app/Komoot_AppReview.json\n",
      "10:40:31 INFO:Dataset Labels: transformed_dataset['labels']=['Domain_Level', 'Interaction_Level', '0', 'System_Level']\n",
      "10:40:31 INFO:Class weights: {'0': 1.0, 'Domain_Level': 1.0, 'Interaction_Level': 1.0, 'System_Level': 1.0}\n",
      "10:40:31 INFO:Configured maximal token sequence length: max_len = 123\n",
      "10:40:34 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/auspicious-croc-607/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/auspicious-croc-607/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/auspicious-croc-607/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/auspicious-croc-607/0_data_test.csv')]\n",
      "10:40:34 INFO:Starting iteration=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7ae88e19da491e80fb338d66ea8bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2488 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcf6a22600f4bffbbfe6f671a193618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/622 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:41:46 INFO:Logged iteration result res.precision=0.7448315652306485 res.recall=0.7329953881360559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34498119354248047, 'eval_step': 0, 'eval_precision': 0.7448315652306485, 'eval_recall': 0.7329953881360559, 'eval_label_count': 4, 'eval_runtime': 5.2449, 'eval_samples_per_second': 118.592, 'eval_steps_per_second': 3.813, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:42:57 INFO:Logged iteration result res.precision=0.7534383658104413 res.recall=0.7500822024701829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3281768560409546, 'eval_step': 2, 'eval_precision': 0.7534383658104413, 'eval_recall': 0.7500822024701829, 'eval_label_count': 4, 'eval_runtime': 5.0288, 'eval_samples_per_second': 123.688, 'eval_steps_per_second': 3.977, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:44:08 INFO:Logged iteration result res.precision=0.7596953062648087 res.recall=0.7564701926066737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3337039351463318, 'eval_step': 4, 'eval_precision': 0.7596953062648087, 'eval_recall': 0.7564701926066737, 'eval_label_count': 4, 'eval_runtime': 4.9906, 'eval_samples_per_second': 124.634, 'eval_steps_per_second': 4.008, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:45:19 INFO:Logged iteration result res.precision=0.7647277950675371 res.recall=0.7527890121521682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3423565924167633, 'eval_step': 6, 'eval_precision': 0.7647277950675371, 'eval_recall': 0.7527890121521682, 'eval_label_count': 4, 'eval_runtime': 5.0374, 'eval_samples_per_second': 123.476, 'eval_steps_per_second': 3.97, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:46:29 INFO:Logged iteration result res.precision=0.7680200436698275 res.recall=0.7558824750001193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3467903137207031, 'eval_step': 8, 'eval_precision': 0.7680200436698275, 'eval_recall': 0.7558824750001193, 'eval_label_count': 4, 'eval_runtime': 4.9791, 'eval_samples_per_second': 124.922, 'eval_steps_per_second': 4.017, 'epoch': 5.0}\n",
      "{'train_runtime': 355.7713, 'train_samples_per_second': 34.966, 'train_steps_per_second': 1.096, 'train_loss': 0.28190397604917866, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10:46:38 INFO:Logged iteration result res.precision=0.7534383658104413 res.recall=0.7500822024701829\n",
      "10:46:39 INFO:Logged iteration result res.precision=0.7534383658104413 res.recall=0.7500822024701829\n",
      "10:46:39 INFO:Finished iteration=0\n",
      "10:46:39 INFO:Logging model artifact (might take a while)\n",
      "10:48:14 INFO:Breaking early after iteration=0 of 5 folds\n",
      "10:48:15 INFO:Logged experiment result res.mean_precision=0.7534383658104413 res.mean_recall=0.7500822024701829\n",
      "10:48:15 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2ced2fa62a254611abca1d3af07e013e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BERTConfig, BERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_1_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_1_experiment_config.name = \"Production\"\n",
    "bert_1_experiment_config.force = True\n",
    "\n",
    "bert_1_config = BERT(max_len=123)\n",
    "\n",
    "\n",
    "bert_1_cfg = OmegaConf.structured(\n",
    "    BERTConfig(\n",
    "        bert=bert_1_config,\n",
    "        experiment=bert_1_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bert import bert\n",
    "\n",
    "    bert(OmegaConf.create(bert_1_cfg))\n",
    "\n",
    "bert_1_run_id = get_run_id(bert_1_cfg, pin_commit=pin_commits)\n",
    "\n",
    "print(bert_1_run_id)\n",
    "\n",
    "bert_1_run = mlflow.get_run(bert_1_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_1_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_1\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for BERT First Stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:11:46 INFO:\n",
      "first_model_bert:\n",
      "  bert:\n",
      "    model: bert-base-uncased\n",
      "    type: BERT\n",
      "    max_len: 110\n",
      "    train_batch_size: 32\n",
      "    validation_batch_size: 32\n",
      "    number_epochs: 5\n",
      "    learning_rate_bert: 2.0e-05\n",
      "    learning_rate_classifier: 0.01\n",
      "    weight_decay: 0.01\n",
      "    weighted_classes: false\n",
      "  experiment:\n",
      "    name: Production\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Domain_Level\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "    system_level: null\n",
      "first_model_bilstm: null\n",
      "first_model_sner: null\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: Production\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "  system_level: null\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "  system_level: null\n",
      "\n",
      "07:11:46 INFO:New experiment. Running\n",
      "07:11:46 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:11:46 INFO:Using device: mps\n",
      "07:11:47 INFO:Found existing run with run_id: ec3a52b91a4c4ebe95763583e2f818f5 matching the configuration\n",
      "07:11:47 INFO:Downloading run model from mlflow-artifacts:/38/ec3a52b91a4c4ebe95763583e2f818f5/artifacts/0_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:12:04 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "07:12:04 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "07:12:04 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "07:12:07 INFO:Dataset Labels: transformed_dataset['labels']=['Interaction', 'Activity', 'System_Level', 'Task', '0', 'Stakeholder', 'Domain_Data', 'Workspace', 'Interaction_Data', 'System_Function']\n",
      "07:12:07 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "07:12:07 INFO:Configured maximal token sequence length: max_len = 110\n",
      "07:12:08 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/enthused-hen-957/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/enthused-hen-957/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/enthused-hen-957/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/enthused-hen-957/0_data_test.csv')]\n",
      "07:12:08 INFO:Starting iteration=0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b9773084724cdaba5bc1f3522417e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:12:08 INFO:Loading Model\n",
      "07:12:09 INFO:Using device: mps\n",
      "07:12:09 INFO:Creating hint column\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1aa45ee74d4254b41b1e95dbbe296b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9e34c4b6ed41fdaff94d189c682d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:12:43 INFO:Loading Model\n",
      "07:12:43 INFO:Using device: mps\n",
      "07:12:43 INFO:Creating hint column\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "788aaf1081c44eeda6c2693c7642b8ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:13:21 INFO:Logged iteration result res.precision=0.6675078277673936 res.recall=0.6316880036205067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38334932923316956, 'eval_step': 0, 'eval_precision': 0.6675078277673936, 'eval_recall': 0.6316880036205067, 'eval_label_count': 10, 'eval_runtime': 2.2749, 'eval_samples_per_second': 118.248, 'eval_steps_per_second': 3.956, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:13:51 INFO:Logged iteration result res.precision=0.6950434026279945 res.recall=0.6460017381423724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3633381426334381, 'eval_step': 2, 'eval_precision': 0.6950434026279945, 'eval_recall': 0.6460017381423724, 'eval_label_count': 10, 'eval_runtime': 2.2431, 'eval_samples_per_second': 119.921, 'eval_steps_per_second': 4.012, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:14:20 INFO:Logged iteration result res.precision=0.7245306308415692 res.recall=0.6812385477840243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35096409916877747, 'eval_step': 4, 'eval_precision': 0.7245306308415692, 'eval_recall': 0.6812385477840243, 'eval_label_count': 10, 'eval_runtime': 2.1976, 'eval_samples_per_second': 122.408, 'eval_steps_per_second': 4.095, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:14:50 INFO:Logged iteration result res.precision=0.7011409677525176 res.recall=0.6533480467054927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3634767532348633, 'eval_step': 6, 'eval_precision': 0.7011409677525176, 'eval_recall': 0.6533480467054927, 'eval_label_count': 10, 'eval_runtime': 2.1951, 'eval_samples_per_second': 122.547, 'eval_steps_per_second': 4.1, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:15:19 INFO:Logged iteration result res.precision=0.6980975323342593 res.recall=0.6570924951464788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36366090178489685, 'eval_step': 8, 'eval_precision': 0.6980975323342593, 'eval_recall': 0.6570924951464788, 'eval_label_count': 10, 'eval_runtime': 2.2006, 'eval_samples_per_second': 122.24, 'eval_steps_per_second': 4.09, 'epoch': 5.0}\n",
      "{'train_runtime': 149.136, 'train_samples_per_second': 36.041, 'train_steps_per_second': 1.14, 'train_loss': 0.3030788197236903, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:15:25 INFO:Logged iteration result res.precision=0.7245306308415692 res.recall=0.6812385477840243\n",
      "07:15:25 INFO:Logged iteration result res.precision=0.7245306308415692 res.recall=0.6812385477840243\n",
      "07:15:25 INFO:Finished iteration=0\n",
      "07:15:25 INFO:Logging model artifact (might take a while)\n",
      "07:18:24 INFO:Breaking early after iteration=0 of 5 folds\n",
      "07:18:25 INFO:Logged experiment result res.mean_precision=0.7245306308415692 res.mean_recall=0.6812385477840243\n",
      "07:18:25 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394f57d85bed4aaba003b0cee28c68f7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_bert')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_bert_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_bert_experiment_config.name = \"Production\"\n",
    "\n",
    "bert_2_bert_config = StagedBERT(max_len=123)\n",
    "\n",
    "bert_2_bert_cfg: DualModelStagedBERTConfig = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_bert_config,\n",
    "        experiment=bert_2_bert_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_bert=bert_1_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_bert_cfg))\n",
    "\n",
    "bert_2_bert_run_id = get_run_id(bert_2_bert_cfg, pin_commit=pin_commits)\n",
    "\n",
    "print(bert_2_bert_run_id)\n",
    "\n",
    "bert_2_bert_run = mlflow.get_run(bert_2_bert_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_bert_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_bert\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_2_bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for SNER First Stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:18:47 INFO:\n",
      "first_model_bert: null\n",
      "first_model_bilstm: null\n",
      "first_model_sner:\n",
      "  sner:\n",
      "    type: SNER\n",
      "  experiment:\n",
      "    name: Production\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Domain_Level\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "    system_level: null\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: Production\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "  system_level: null\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "  system_level: null\n",
      "\n",
      "07:18:47 INFO:New experiment. Running\n",
      "07:18:47 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:18:48 INFO:Using device: mps\n",
      "07:18:48 INFO:Found existing run with run_id: 0ac2a21d9e2c4cd3a984cfd6d5616f25 matching the configuration\n",
      "07:18:48 INFO:Downloading run model from mlflow-artifacts:/38/0ac2a21d9e2c4cd3a984cfd6d5616f25/artifacts/0_model.ser.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:18:49 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "07:18:49 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "07:18:49 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: c7b57270-4af9-4247-8e9b-e4b5a9e96db5)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json\n",
      "07:19:01 WARNING:'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: c7b57270-4af9-4247-8e9b-e4b5a9e96db5)')' thrown while requesting HEAD https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json\n",
      "07:19:01 INFO:Dataset Labels: transformed_dataset['labels']=['Interaction', 'Activity', 'System_Level', 'Task', '0', 'Stakeholder', 'Domain_Data', 'Workspace', 'Interaction_Data', 'System_Function']\n",
      "07:19:01 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "07:19:01 INFO:Configured maximal token sequence length: max_len = 110\n",
      "07:19:03 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/flawless-mule-943/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/flawless-mule-943/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/flawless-mule-943/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/flawless-mule-943/0_data_test.csv')]\n",
      "07:19:03 INFO:Starting iteration=0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d413828e504445cbb0a0ddb85209c985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e104c4c01c314bd88efff0841d6c08fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:19:38 INFO:Logged iteration result res.precision=0.6754658112454573 res.recall=0.6221767408632006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.38078516721725464, 'eval_step': 0, 'eval_precision': 0.6754658112454573, 'eval_recall': 0.6221767408632006, 'eval_label_count': 10, 'eval_runtime': 2.3576, 'eval_samples_per_second': 114.101, 'eval_steps_per_second': 3.818, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:20:08 INFO:Logged iteration result res.precision=0.7060137118065192 res.recall=0.6299854292953236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.35421010851860046, 'eval_step': 2, 'eval_precision': 0.7060137118065192, 'eval_recall': 0.6299854292953236, 'eval_label_count': 10, 'eval_runtime': 2.1802, 'eval_samples_per_second': 123.383, 'eval_steps_per_second': 4.128, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:20:38 INFO:Logged iteration result res.precision=0.7212585410998176 res.recall=0.6578305924888609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34980329871177673, 'eval_step': 4, 'eval_precision': 0.7212585410998176, 'eval_recall': 0.6578305924888609, 'eval_label_count': 10, 'eval_runtime': 2.1743, 'eval_samples_per_second': 123.719, 'eval_steps_per_second': 4.139, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:21:07 INFO:Logged iteration result res.precision=0.6785963397508594 res.recall=0.6251045901344251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3639702796936035, 'eval_step': 6, 'eval_precision': 0.6785963397508594, 'eval_recall': 0.6251045901344251, 'eval_label_count': 10, 'eval_runtime': 2.0724, 'eval_samples_per_second': 129.799, 'eval_steps_per_second': 4.343, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:21:37 INFO:Logged iteration result res.precision=0.6869321738971563 res.recall=0.6311597665520065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36528241634368896, 'eval_step': 8, 'eval_precision': 0.6869321738971563, 'eval_recall': 0.6311597665520065, 'eval_label_count': 10, 'eval_runtime': 2.2077, 'eval_samples_per_second': 121.844, 'eval_steps_per_second': 4.077, 'epoch': 5.0}\n",
      "{'train_runtime': 151.1739, 'train_samples_per_second': 35.555, 'train_steps_per_second': 1.125, 'train_loss': 0.24500407050637638, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:21:42 INFO:Logged iteration result res.precision=0.7212585410998176 res.recall=0.6578305924888609\n",
      "07:21:43 INFO:Logged iteration result res.precision=0.7212585410998176 res.recall=0.6578305924888609\n",
      "07:21:43 INFO:Finished iteration=0\n",
      "07:21:43 INFO:Logging model artifact (might take a while)\n",
      "07:23:18 INFO:Breaking early after iteration=0 of 5 folds\n",
      "07:23:19 INFO:Logged experiment result res.mean_precision=0.7212585410998176 res.mean_recall=0.6578305924888609\n",
      "07:23:19 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1219d6e29446499890406e8151ef7b63\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_sner')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_sner_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_sner_experiment_config.name = \"Production\"\n",
    "\n",
    "bert_2_sner_config = StagedBERT(max_len=123)\n",
    "\n",
    "bert_2_sner_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_sner_config,\n",
    "        experiment=bert_2_sner_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_sner=sner_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_sner_cfg))\n",
    "\n",
    "bert_2_sner_run_id = get_run_id(bert_2_sner_cfg, pin_commit=pin_commits)\n",
    "\n",
    "print(bert_2_sner_run_id)\n",
    "\n",
    "bert_2_sner_run = mlflow.get_run(bert_2_sner_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_sner_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_sner\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_2_sner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for BILSTM First Stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:26:53 INFO:\n",
      "first_model_bert: null\n",
      "first_model_bilstm:\n",
      "  bilstm:\n",
      "    type: BiLSTM\n",
      "    sentence_length: 110\n",
      "    batch_size: 32\n",
      "    number_epochs: 4\n",
      "    verbose: 1\n",
      "    weighted_classes: false\n",
      "    learning_rate: 0.0001\n",
      "  experiment:\n",
      "    name: Production\n",
      "    description: ''\n",
      "    random_state: 125\n",
      "    folds: 5\n",
      "    iterations: 1\n",
      "    average: macro\n",
      "    dataset: prolific\n",
      "    lower_case: false\n",
      "    force: false\n",
      "  transformation:\n",
      "    description: Levels\n",
      "    type: Reduced\n",
      "    task: Domain_Level\n",
      "    goals: null\n",
      "    domain_data: Domain_Level\n",
      "    activity: Domain_Level\n",
      "    stakeholder: Domain_Level\n",
      "    system_function: Interaction_Level\n",
      "    interaction: Interaction_Level\n",
      "    interaction_data: Interaction_Level\n",
      "    workspace: Interaction_Level\n",
      "    software: System_Level\n",
      "    internal_action: System_Level\n",
      "    internal_data: System_Level\n",
      "    system_level: null\n",
      "first_model_sner: null\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "  layers: []\n",
      "experiment:\n",
      "  name: Production\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "  system_level: null\n",
      "hint_transformation:\n",
      "  description: ???\n",
      "  type: ???\n",
      "  task: null\n",
      "  goals: null\n",
      "  domain_data: null\n",
      "  activity: null\n",
      "  stakeholder: null\n",
      "  system_function: null\n",
      "  interaction: null\n",
      "  interaction_data: null\n",
      "  workspace: null\n",
      "  software: null\n",
      "  internal_action: null\n",
      "  internal_data: null\n",
      "  system_level: null\n",
      "\n",
      "07:26:53 INFO:New experiment. Running\n",
      "07:26:53 INFO:Entering mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:26:53 INFO:Using device: mps\n",
      "07:26:53 INFO:Found existing run with run_id: 46aa06deee964d17905524b1ad721245 matching the configuration\n",
      "07:26:53 INFO:Downloading run model from mlflow-artifacts:/38/46aa06deee964d17905524b1ad721245/artifacts/0_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:26:55 INFO:loading projection weights from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz\n",
      "07:27:30 INFO:KeyedVectors lifecycle event {'msg': 'loaded (1193514, 100) matrix of type float32 from /Users/bockstaller/gensim-data/glove-twitter-100/glove-twitter-100.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-08-28T19:27:30.978685', 'gensim': '4.3.1', 'python': '3.11.4 (main, Jun 20 2023, 19:14:10) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.3-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n",
      "07:27:31 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_1_33.json\n",
      "07:27:31 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_34_66.json\n",
      "07:27:31 INFO:Importing dataset: prolific from /Users/bockstaller/code/uvl-tore-classifier-bert/src/data/datasets/prolific/TORE_Coded_Answers_67_100.json\n",
      "07:27:33 INFO:Dataset Labels: transformed_dataset['labels']=['Interaction', 'Activity', 'System_Level', 'Task', '0', 'Stakeholder', 'Domain_Data', 'Workspace', 'Interaction_Data', 'System_Function']\n",
      "07:27:33 INFO:Class weights: {'0': 1.0, 'Task': 1.0, 'Domain_Data': 1.0, 'Activity': 1.0, 'Stakeholder': 1.0, 'System_Function': 1.0, 'Interaction': 1.0, 'Interaction_Data': 1.0, 'Workspace': 1.0, 'System_Level': 1.0}\n",
      "07:27:33 INFO:Configured maximal token sequence length: max_len = 110\n",
      "07:27:35 INFO:Created fold datasets for fold: 0, stored at paths=[PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/bittersweet-pig-337/0_data_train.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/bittersweet-pig-337/0_data_train.csv'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/bittersweet-pig-337/0_data_test.pickle'), PosixPath('/Users/bockstaller/code/uvl-tore-classifier-bert/src/data/temp/sampling/bittersweet-pig-337/0_data_test.csv')]\n",
      "07:27:35 INFO:Starting iteration=0\n",
      "2023-08-28 19:27:52.758309: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-28 19:27:52.893846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-28 19:27:52.907162: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/34 [===>..........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 19:27:52.973992: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-28 19:27:52.986381: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 2s 28ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b5fa8eba6fd47f0a5ea6b466fb1df8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1075 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 19:28:01.113841: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-28 19:28:01.234551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-28 19:28:01.248651: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-28 19:28:01.305962: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/9 [===============>..............] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-28 19:28:01.317846: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 35ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1badefbd9751428ba50aa94a050304fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/269 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:28:32 INFO:Logged iteration result res.precision=0.6680461931378503 res.recall=0.6199965235756286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.39321935176849365, 'eval_step': 0, 'eval_precision': 0.6680461931378503, 'eval_recall': 0.6199965235756286, 'eval_label_count': 10, 'eval_runtime': 2.1874, 'eval_samples_per_second': 122.974, 'eval_steps_per_second': 4.114, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:29:01 INFO:Logged iteration result res.precision=0.694559879687572 res.recall=0.6371689388907558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3638952672481537, 'eval_step': 2, 'eval_precision': 0.694559879687572, 'eval_recall': 0.6371689388907558, 'eval_label_count': 10, 'eval_runtime': 2.1, 'eval_samples_per_second': 128.096, 'eval_steps_per_second': 4.286, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:29:30 INFO:Logged iteration result res.precision=0.7149316221462662 res.recall=0.6787447630552844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3512847125530243, 'eval_step': 4, 'eval_precision': 0.7149316221462662, 'eval_recall': 0.6787447630552844, 'eval_label_count': 10, 'eval_runtime': 2.1298, 'eval_samples_per_second': 126.301, 'eval_steps_per_second': 4.226, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:30:00 INFO:Logged iteration result res.precision=0.701081362071734 res.recall=0.652372461383967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3632904887199402, 'eval_step': 6, 'eval_precision': 0.701081362071734, 'eval_recall': 0.652372461383967, 'eval_label_count': 10, 'eval_runtime': 2.1378, 'eval_samples_per_second': 125.828, 'eval_steps_per_second': 4.21, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:30:32 INFO:Logged iteration result res.precision=0.7025782526868951 res.recall=0.6541316762715507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.36204540729522705, 'eval_step': 8, 'eval_precision': 0.7025782526868951, 'eval_recall': 0.6541316762715507, 'eval_label_count': 10, 'eval_runtime': 2.3672, 'eval_samples_per_second': 113.637, 'eval_steps_per_second': 3.802, 'epoch': 5.0}\n",
      "{'train_runtime': 152.1069, 'train_samples_per_second': 35.337, 'train_steps_per_second': 1.118, 'train_loss': 0.31860966401941637, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:30:39 INFO:Logged iteration result res.precision=0.7149316221462662 res.recall=0.6787447630552844\n",
      "07:30:40 INFO:Logged iteration result res.precision=0.7149316221462662 res.recall=0.6787447630552844\n",
      "07:30:40 INFO:Finished iteration=0\n",
      "07:30:40 INFO:Logging model artifact (might take a while)\n",
      "07:32:23 INFO:Breaking early after iteration=0 of 5 folds\n",
      "07:32:24 INFO:Logged experiment result res.mean_precision=0.7149316221462662 res.mean_recall=0.6787447630552844\n",
      "07:32:25 INFO:Left mlflow context\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82b0e7e4c2b041ddaddcb0261283ceef\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_bilstm')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_bilstm_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_bilstm_experiment_config.name = \"Production\"\n",
    "\n",
    "bert_2_bilstm_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_bilstm_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_bilstm_config,\n",
    "        experiment=bert_2_bilstm_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_bilstm=bilstm_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_bilstm_cfg))\n",
    "\n",
    "bert_2_bilstm_run_id = get_run_id(bert_2_bilstm_cfg, pin_commit=pin_commits)\n",
    "\n",
    "print(bert_2_bilstm_run_id)\n",
    "\n",
    "bert_2_bilstm_run = mlflow.get_run(bert_2_bilstm_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_bilstm_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_bilstm\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\n",
    "    \"./src/service/models/bert_2_bilstm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT E2E Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "07:32:42 INFO:\n",
      "bert:\n",
      "  model: bert-base-uncased\n",
      "  type: BERT\n",
      "  max_len: 110\n",
      "  train_batch_size: 32\n",
      "  validation_batch_size: 32\n",
      "  number_epochs: 5\n",
      "  learning_rate_bert: 2.0e-05\n",
      "  learning_rate_classifier: 0.01\n",
      "  weight_decay: 0.01\n",
      "  weighted_classes: false\n",
      "experiment:\n",
      "  name: Production\n",
      "  description: ''\n",
      "  random_state: 125\n",
      "  folds: 5\n",
      "  iterations: 1\n",
      "  average: macro\n",
      "  dataset: prolific\n",
      "  lower_case: false\n",
      "  force: false\n",
      "transformation:\n",
      "  description: None\n",
      "  type: Full\n",
      "  task: Task\n",
      "  goals: null\n",
      "  domain_data: Domain_Data\n",
      "  activity: Activity\n",
      "  stakeholder: Stakeholder\n",
      "  system_function: System_Function\n",
      "  interaction: Interaction\n",
      "  interaction_data: Interaction_Data\n",
      "  workspace: Workspace\n",
      "  software: System_Level\n",
      "  internal_action: System_Level\n",
      "  internal_data: System_Level\n",
      "  system_level: null\n",
      "\n",
      "07:32:42 WARNING:Experiment was already run, aborting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "394f57d85bed4aaba003b0cee28c68f7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BERTConfig, BERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_experiment_config.name = \"Production\"\n",
    "\n",
    "bert_config = BERT(max_len=sentence_length)\n",
    "\n",
    "bert_cfg = OmegaConf.structured(\n",
    "    BERTConfig(\n",
    "        bert=bert_config,\n",
    "        experiment=bert_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bert import bert\n",
    "\n",
    "    bert(OmegaConf.create(bert_cfg))\n",
    "\n",
    "bert_run_id = get_run_id(bert_cfg, pin_commit=pin_commits)\n",
    "\n",
    "print(bert_run_id)\n",
    "\n",
    "run = mlflow.get_run(bert_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{run.info.artifact_uri}/0_model\", dst_path=Path(\"./src/service/models/\")\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
