{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import shutil\n",
    "from omegaconf import OmegaConf\n",
    "from hydra import initialize, compose\n",
    "from hydra.core.config_store import ConfigStore\n",
    "import mlflow\n",
    "from src.experiments.sner import sner\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s %(levelname)s:%(message)s\",\n",
    "    level=logging.INFO,\n",
    "    datefmt=\"%I:%M:%S\",\n",
    ")\n",
    "logger = logging.getLogger(\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_experiments=False\n",
      "pin_commits=False\n"
     ]
    }
   ],
   "source": [
    "sentence_length = 110\n",
    "\n",
    "run_experiments = os.getenv(\"UVL_BERT_RUN_EXPERIMENTS\",False) == \"False\"\n",
    "pin_commits = os.getenv(\"UVL_BERT_PIN_COMMITS\",False) == \"False\"\n",
    "\n",
    "print(f\"{run_experiments=}\")\n",
    "print(f\"{pin_commits=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tooling.config import Experiment, Transformation\n",
    "\n",
    "base_experiment_config = Experiment(\n",
    "    name=\"Base Config\", iterations=1, force=False\n",
    ")\n",
    "\n",
    "levels_transformation_config = Transformation(\n",
    "    description=\"Levels\",\n",
    "    type=\"Reduced\",\n",
    "    task=\"Domain_Level\",\n",
    "    domain_data=\"Domain_Level\",\n",
    "    activity=\"Activity\",\n",
    "    stakeholder=\"Domain_Level\",\n",
    "    system_function=\"Interaction_Level\",\n",
    "    interaction=\"Interaction_Level\",\n",
    "    interaction_data=\"Interaction_Level\",\n",
    "    workspace=\"Interaction_Level\",\n",
    "    software=\"System_Level\",\n",
    "    internal_action=\"System_Level\",\n",
    "    internal_data=\"System_Level\",\n",
    ")\n",
    "\n",
    "label_transformation_config = Transformation(\n",
    "    description=\"None\",\n",
    "    type=\"Full\",\n",
    "    task=\"Task\",\n",
    "    domain_data=\"Domain_Data\",\n",
    "    activity=\"Activity\",\n",
    "    stakeholder=\"Stakeholder\",\n",
    "    system_function=\"System_Function\",\n",
    "    interaction=\"Interaction\",\n",
    "    interaction_data=\"Interaction_Data\",\n",
    "    workspace=\"Workspace\",\n",
    "    software=\"System_Level\",\n",
    "    internal_action=\"System_Level\",\n",
    "    internal_data=\"System_Level\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:59:05 INFO:Hint Label2Id: hint_label2id={'0': 0, 'Activity': 1, 'Domain_Level': 2, 'Interaction_Level': 3, 'System_Level': 4}\n",
      "01:59:05 INFO:Hint Label2Id: hint_label2id={'0': 0, 'Task': 1, 'Domain_Data': 2, 'Activity': 3, 'Stakeholder': 4, 'System_Function': 5, 'Interaction': 6, 'Interaction_Data': 7, 'Workspace': 8, 'System_Level': 9}\n"
     ]
    }
   ],
   "source": [
    "from tooling.transformation import get_hint_transformation\n",
    "import pickle\n",
    "\n",
    "hint_transformation = get_hint_transformation(\n",
    "    transformation_cfg=OmegaConf.structured(levels_transformation_config)\n",
    ")\n",
    "hint_label2id = hint_transformation[\"label2id\"]\n",
    "pickle.dump(\n",
    "    hint_label2id, open(\"./src/service/models/hint_label2id.pickle\", \"wb\")\n",
    ")\n",
    "hint_id2label = {y: x for x, y in hint_label2id.items()}\n",
    "pickle.dump(\n",
    "    hint_id2label, open(\"./src/service/models/hint_id2label.pickle\", \"wb\")\n",
    ")\n",
    "\n",
    "transformation = get_hint_transformation(\n",
    "    transformation_cfg=OmegaConf.structured(label_transformation_config)\n",
    ")\n",
    "label2id = transformation[\"label2id\"]\n",
    "pickle.dump(label2id, open(\"./src/service/models/label2id.pickle\", \"wb\"))\n",
    "id2label = {y: x for x, y in label2id.items()}\n",
    "pickle.dump(id2label, open(\"./src/service/models/id2label.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BiLSTM First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://bockstaller.cc\n",
      "b96e3ab36442411db9d365dd5ff5d3e5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bilstm')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BiLSTMConfig, BiLSTM\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bilstm_experiment_config = deepcopy(base_experiment_config)\n",
    "bilstm_experiment_config.name = \"BiLSTM Train for Staged Application\"\n",
    "\n",
    "bilstm_config = BiLSTM(sentence_length=sentence_length)\n",
    "\n",
    "bilstm_cfg = OmegaConf.structured(\n",
    "    BiLSTMConfig(\n",
    "        bilstm=bilstm_config,\n",
    "        experiment=bilstm_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bilstm import bilstm\n",
    "    bilstm(bilstm_cfg)\n",
    "\n",
    "print(mlflow.get_tracking_uri())\n",
    "\n",
    "\n",
    "bilstm_run_id = get_run_id(bilstm_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bilstm_run_id)\n",
    "\n",
    "bilstm_run = mlflow.get_run(bilstm_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bilstm_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bilstm\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bilstm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train SNER First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20f5a21e0e7a484f8f8a248a74f0198b\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/sner.ser.gz')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import SNERConfig, SNER\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "sner_experiment_config = deepcopy(base_experiment_config)\n",
    "sner_experiment_config.name = \"SNER Train for Staged Application\"\n",
    "\n",
    "sner_config = SNER()\n",
    "\n",
    "sner_cfg = OmegaConf.structured(\n",
    "    SNERConfig(\n",
    "        sner=sner_config,\n",
    "        experiment=sner_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.sner import sner\n",
    "    sner(OmegaConf.create(sner_cfg))\n",
    "\n",
    "sner_run_id = get_run_id(sner_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(sner_run_id)\n",
    "\n",
    "sner_run = mlflow.get_run(sner_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{sner_run.info.artifact_uri}/0_model.ser.gz\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    Path(\"./src/service/models/sner.ser.gz\").unlink()\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model.ser.gz\").rename(\n",
    "    \"./src/service/models/sner.ser.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT First Stage Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66d4b382cc4944be93de19d0af2a8826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:59:23 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:59:23 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:59:23 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:59:23 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:59:23 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:59:23 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_1')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BERTConfig, BERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_1_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_1_experiment_config.name = \"BERT_1 Train for Staged Application\"\n",
    "\n",
    "bert_1_config = BERT(max_len=sentence_length)\n",
    "\n",
    "bert_1_cfg = OmegaConf.structured(\n",
    "    BERTConfig(\n",
    "        bert=bert_1_config,\n",
    "        experiment=bert_1_experiment_config,\n",
    "        transformation=levels_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bert import bert\n",
    "    bert(OmegaConf.create(bert_1_cfg))\n",
    "\n",
    "bert_1_run_id = get_run_id(bert_1_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_1_run_id)\n",
    "\n",
    "bert_1_run = mlflow.get_run(bert_1_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_1_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_1\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for BERT First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d8c07b4055614a4ebdf270f4f30ba61e\n"
     ]
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_bert_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_bert_experiment_config.name = \"BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_bert_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_bert_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_bert_config,\n",
    "        experiment=bert_2_bert_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_bert=bert_1_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_bert_cfg))\n",
    "\n",
    "bert_2_bert_run_id = get_run_id(bert_2_bert_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_bert_run_id)\n",
    "\n",
    "bert_2_bert_run = mlflow.get_run(bert_2_bert_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_bert_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_bert\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_2_bert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for SNER First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b15214708cf7420f90cffcc10b1cc845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:32:43 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:32:43 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:32:44 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:32:44 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:32:44 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:32:44 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert_2_sner')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_sner_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_sner_experiment_config.name = \"BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_sner_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_sner_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_sner_config,\n",
    "        experiment=bert_2_sner_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_sner=sner_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_sner_cfg))\n",
    "\n",
    "bert_2_sner_run_id = get_run_id(bert_2_sner_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_sner_run_id)\n",
    "\n",
    "bert_2_sner_run = mlflow.get_run(bert_2_sner_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_sner_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_sner\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert_2_sner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Second Stage Model for BILSTM First Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mexperiments\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdual_model_staged_bert\u001b[39;00m \u001b[39mimport\u001b[39;00m dual_stage_bert\n\u001b[1;32m     22\u001b[0m     dual_stage_bert(OmegaConf\u001b[39m.\u001b[39mcreate(bert_2_bilstm_cfg))\n\u001b[0;32m---> 24\u001b[0m bert_2_bilstm_run_id \u001b[39m=\u001b[39m get_run_id(bert_2_bilstm_cfg, pin_commit \u001b[39m=\u001b[39;49m pin_commits)\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(bert_2_bilstm_run_id)\n\u001b[1;32m     28\u001b[0m bert_2_bilstm_run \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39mget_run(bert_2_bilstm_run_id)\n",
      "File \u001b[0;32m~/code/uvl-tore-classifier-bert/src/tooling/observability.py:117\u001b[0m, in \u001b[0;36mget_run_id\u001b[0;34m(cfg, pin_commit)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_run_id\u001b[39m(\n\u001b[1;32m    114\u001b[0m     cfg: Config, pin_commit: \u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    115\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39mstr\u001b[39m]:\n\u001b[1;32m    116\u001b[0m     experiment_id \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39mset_experiment(cfg\u001b[39m.\u001b[39mexperiment\u001b[39m.\u001b[39mname)\n\u001b[0;32m--> 117\u001b[0m     runs_df \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39;49msearch_runs(\n\u001b[1;32m    118\u001b[0m         experiment_ids\u001b[39m=\u001b[39;49m[experiment_id\u001b[39m.\u001b[39;49mexperiment_id], output_format\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpandas\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m    119\u001b[0m     )\n\u001b[1;32m    120\u001b[0m     runs_df\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m), inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    122\u001b[0m     config \u001b[39m=\u001b[39m flatten(\n\u001b[1;32m    123\u001b[0m         cast(Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m], OmegaConf\u001b[39m.\u001b[39mto_container(cfg, resolve\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)),\n\u001b[1;32m    124\u001b[0m         separator\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    125\u001b[0m     )\n",
      "File \u001b[0;32m~/code/uvl-tore-classifier-bert/venv/lib/python3.11/site-packages/mlflow/tracking/fluent.py:1757\u001b[0m, in \u001b[0;36msearch_runs\u001b[0;34m(experiment_ids, filter_string, run_view_type, max_results, order_by, output_format, search_all_experiments, experiment_names)\u001b[0m\n\u001b[1;32m   1755\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m tags\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   1756\u001b[0m         data[\u001b[39m\"\u001b[39m\u001b[39mtags.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m key] \u001b[39m=\u001b[39m value\n\u001b[0;32m-> 1757\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39;49mDataFrame(data)\n\u001b[1;32m   1758\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1759\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1760\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnsupported output format: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m. Supported string values are \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpandas\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlist\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1761\u001b[0m         \u001b[39m%\u001b[39m output_format\n\u001b[1;32m   1762\u001b[0m     )\n",
      "File \u001b[0;32m~/code/uvl-tore-classifier-bert/venv/lib/python3.11/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[1;32m    710\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m \u001b[39mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/code/uvl-tore-classifier-bert/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[39m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[39m=\u001b[39m [x\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m x \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[0;32m~/code/uvl-tore-classifier-bert/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[1;32m    119\u001b[0m     \u001b[39m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     arrays, refs \u001b[39m=\u001b[39m _homogenize(arrays, index, dtype)\n\u001b[1;32m    121\u001b[0m     \u001b[39m# _homogenize ensures\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     \u001b[39m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[1;32m    123\u001b[0m     \u001b[39m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    128\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/code/uvl-tore-classifier-bert/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:607\u001b[0m, in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    604\u001b[0m         val \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(val)\n\u001b[1;32m    605\u001b[0m     val \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mfast_multiget(val, oindex\u001b[39m.\u001b[39m_values, default\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mnan)\n\u001b[0;32m--> 607\u001b[0m val \u001b[39m=\u001b[39m sanitize_array(val, index, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    608\u001b[0m com\u001b[39m.\u001b[39mrequire_length_match(val, index)\n\u001b[1;32m    609\u001b[0m refs\u001b[39m.\u001b[39mappend(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/code/uvl-tore-classifier-bert/venv/lib/python3.11/site-packages/pandas/core/construction.py:605\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    603\u001b[0m         \u001b[39mif\u001b[39;00m subarr\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m    604\u001b[0m             subarr \u001b[39m=\u001b[39m cast(np\u001b[39m.\u001b[39mndarray, subarr)\n\u001b[0;32m--> 605\u001b[0m             subarr \u001b[39m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m    607\u001b[0m subarr \u001b[39m=\u001b[39m _sanitize_ndim(subarr, data, dtype, index, allow_2d\u001b[39m=\u001b[39mallow_2d)\n\u001b[1;32m    609\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(subarr, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    610\u001b[0m     \u001b[39m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n",
      "File \u001b[0;32m~/code/uvl-tore-classifier-bert/venv/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:1171\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[39m# error: Incompatible return value type (got \"Union[str, Union[dtype[Any],\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m     \u001b[39m# ExtensionDtype]]\", expected \"Union[dtype[Any], ExtensionDtype]\")\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m     \u001b[39mreturn\u001b[39;00m inferred_dtype  \u001b[39m# type: ignore[return-value]\u001b[39;00m\n\u001b[0;32m-> 1171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmaybe_infer_to_datetimelike\u001b[39m(\n\u001b[1;32m   1172\u001b[0m     value: npt\u001b[39m.\u001b[39mNDArray[np\u001b[39m.\u001b[39mobject_],\n\u001b[1;32m   1173\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray \u001b[39m|\u001b[39m DatetimeArray \u001b[39m|\u001b[39m TimedeltaArray \u001b[39m|\u001b[39m PeriodArray \u001b[39m|\u001b[39m IntervalArray:\n\u001b[1;32m   1174\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39m    we might have a array (or single object) that is datetime like,\u001b[39;00m\n\u001b[1;32m   1176\u001b[0m \u001b[39m    and no dtype is passed don't change the value unless we find a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \n\u001b[1;32m   1190\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, np\u001b[39m.\u001b[39mndarray) \u001b[39mor\u001b[39;00m value\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m \u001b[39mobject\u001b[39m:\n\u001b[1;32m   1192\u001b[0m         \u001b[39m# Caller is responsible for passing only ndarray[object]\u001b[39;00m\n",
      "File \u001b[0;32m~/code/uvl-tore-classifier-bert/venv/lib/python3.11/site-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_trace_dispatch_regular.py:326\u001b[0m, in \u001b[0;36mThreadTracer.__call__\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_args \u001b[39m=\u001b[39m args\n\u001b[1;32m    324\u001b[0m \u001b[39m# ENDIF\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, frame, event, arg):\n\u001b[1;32m    327\u001b[0m \u001b[39m        \u001b[39m\u001b[39m''' This is the callback used when we enter some context in the debugger.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \n\u001b[1;32m    329\u001b[0m \u001b[39m        We also decorate the thread we are in with info about the debugging.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39m            This is the global debugger (this method should actually be added as a method to it).\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39m        '''\u001b[39;00m\n\u001b[1;32m    339\u001b[0m         \u001b[39m# IFDEF CYTHON\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         \u001b[39m# cdef str filename;\u001b[39;00m\n\u001b[1;32m    341\u001b[0m         \u001b[39m# cdef str base;\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[39m# DEBUG = 'code_to_debug' in frame.f_code.co_filename\u001b[39;00m\n\u001b[1;32m    351\u001b[0m         \u001b[39m# if DEBUG: print('ENTER: trace_dispatch: %s %s %s %s' % (frame.f_code.co_filename, frame.f_lineno, event, frame.f_code.co_name))\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import DualModelStagedBERTConfig, StagedBERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_2_bilstm_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_2_bilstm_experiment_config.name = \"BERT_2 Train for Staged Application\"\n",
    "\n",
    "bert_2_bilstm_config = StagedBERT(max_len=sentence_length)\n",
    "\n",
    "bert_2_bilstm_cfg = OmegaConf.structured(\n",
    "    DualModelStagedBERTConfig(\n",
    "        bert=bert_2_bilstm_config,\n",
    "        experiment=bert_2_bilstm_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "        first_model_bilstm=bilstm_cfg,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.dual_model_staged_bert import dual_stage_bert\n",
    "    dual_stage_bert(OmegaConf.create(bert_2_bilstm_cfg))\n",
    "\n",
    "bert_2_bilstm_run_id = get_run_id(bert_2_bilstm_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_2_bilstm_run_id)\n",
    "\n",
    "bert_2_bilstm_run = mlflow.get_run(bert_2_bilstm_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{bert_2_bilstm_run.info.artifact_uri}/0_model\",\n",
    "    dst_path=Path(\"./src/service/models/\"),\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert_2_bilstm\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\n",
    "    \"./src/service/models/bert_2_bilstm\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT E2E Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9e609bb46052414f91cea9cb5c32f542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:00:04 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:00:04 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:00:04 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:00:04 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:00:04 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n",
      "01:00:04 WARNING:Connection pool is full, discarding connection: ma-mlflow.s3.eu-central-1.amazonaws.com. Connection pool size: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('src/service/models/bert')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tooling.observability import get_run_id\n",
    "from tooling.config import BERTConfig, BERT\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "bert_experiment_config = deepcopy(base_experiment_config)\n",
    "bert_experiment_config.name = \"BERT Train for E2E Application\"\n",
    "\n",
    "bert_config = BERT(max_len=sentence_length)\n",
    "\n",
    "bert_cfg = OmegaConf.structured(\n",
    "    BERTConfig(\n",
    "        bert=bert_config,\n",
    "        experiment=bert_experiment_config,\n",
    "        transformation=label_transformation_config,\n",
    "    )\n",
    ")\n",
    "\n",
    "if run_experiments:\n",
    "    from experiments.bert import bert\n",
    "    bert(OmegaConf.create(bert_cfg))\n",
    "\n",
    "bert_run_id = get_run_id(bert_cfg, pin_commit = pin_commits)\n",
    "\n",
    "print(bert_run_id)\n",
    "\n",
    "run = mlflow.get_run(bert_run_id)\n",
    "mlflow.artifacts.download_artifacts(\n",
    "    f\"{run.info.artifact_uri}/0_model\", dst_path=Path(\"./src/service/models/\")\n",
    ")\n",
    "try:\n",
    "    shutil.rmtree(Path(\"./src/service/models/bert\"))\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "Path(\"./src/service/models/0_model\").rename(\"./src/service/models/bert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
