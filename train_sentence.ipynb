{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train BERT Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Code occurrences in the training data:\n",
      "2: 455\n",
      "0: 900\n",
      "1: 1671\n",
      "3: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch: 1\n",
      "Precision_epoch0: 0.4776051266835982\n",
      "Recall_epoch0: 0.5619295958279009\n",
      "F1_epoch0: 0.5105051702455878\n",
      "Kappa_epoch0: 0.25074573058338523\n",
      "AvgTrainLoss_epoch0: 1.0611148873964946\n",
      "AvgValLoss_epoch0: 4.2444595495859785\n",
      "Eval_Runtime_epoch0: 69.19323396682739\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import json\n",
    "import mlflow\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import time\n",
    "\n",
    "\n",
    "def train_model(data_path, num_epochs, learning_rate, batch_size, oversample_method=False, oversample_labels=None, cross_validation=False):\n",
    "    # Set MLFlow experiment name\n",
    "    mlflow.set_experiment(\"SentenceClass\")\n",
    "\n",
    "    # Check if CUDA is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('Using device:', device)\n",
    "\n",
    "    # Load BERT tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "    #tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "\n",
    "    # Read the JSON file\n",
    "    def read_json(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n",
    "    data = read_json(data_path)\n",
    "\n",
    "    # Extract sentences and labels\n",
    "    sentences = [token['name'] for token in data['tokens']]\n",
    "    labels = [code['tore'] for code in data['codes']]\n",
    "    label_mapping = {'0': 0, 'Domain Level': 1, 'Interaction Level': 2, 'System Level': 3}\n",
    "    #label_mapping = {'0': 0, 'Domain Level': 1, 'Interaction Level': 2}\n",
    "    #label_mapping = {'0': 0, 'System Level': 1}\n",
    "    # label_mapping = {'0': 0, 'Level': 1}\n",
    "    labels = [label_mapping[label] if label in label_mapping else label for label in labels]\n",
    "\n",
    "    # Tokenize input sentences\n",
    "    tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "    # Convert tokens to input IDs\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "    # Pad input sequences\n",
    "    max_len = max(len(x) for x in input_ids)\n",
    "    padded_input_ids = [x + [tokenizer.pad_token_id] * (max_len - len(x)) for x in input_ids]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    input_ids_tensor = torch.tensor(padded_input_ids).to(device)\n",
    "    labels_tensor = torch.tensor(labels).to(device)\n",
    "\n",
    "    # Create attention masks\n",
    "    attention_masks = [[float(i != tokenizer.pad_token_id) for i in ii] for ii in padded_input_ids]\n",
    "\n",
    "    if cross_validation:\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold = 1\n",
    "        avg_precision = 0\n",
    "        avg_recall = 0\n",
    "        avg_f1 = 0\n",
    "\n",
    "        for train_index, val_index in kf.split(input_ids_tensor):\n",
    "            print(f\"Fold {fold}\")\n",
    "\n",
    "            if oversample_method:\n",
    "                # Apply SMOTE to training data for selected labels\n",
    "                if oversample_labels is not None:\n",
    "                    oversample_indices = [i for i, label in enumerate(labels_tensor[train_index]) if label in oversample_labels]\n",
    "                    train_inputs_oversample, train_labels_oversample = input_ids_tensor[train_index][oversample_indices], labels_tensor[train_index][oversample_indices]\n",
    "                else:\n",
    "                    train_inputs_oversample, train_labels_oversample = input_ids_tensor[train_index], labels_tensor[train_index]\n",
    "                    \n",
    "                if oversample_method == \"smote\":\n",
    "                    oversampler = SMOTE(random_state=42)\n",
    "                elif oversample_method == \"adasyn\":\n",
    "                    oversampler = ADASYN(random_state=42)\n",
    "                if oversample_labels==None:\n",
    "                    train_inputs_smote, train_labels_smote = oversampler.fit_resample(input_ids_tensor[train_index], labels_tensor[train_index])\n",
    "                    train_inputs_tensor = torch.tensor(train_inputs_smote).to(device)\n",
    "                    train_labels_tensor = torch.tensor(train_labels_smote).to(device)    \n",
    "                else:\n",
    "                    train_inputs_oversample, train_labels_oversample = oversampler.fit_resample(train_inputs_oversample.cpu().numpy(), train_labels_oversample.cpu().numpy())\n",
    "                    train_inputs_oversample = torch.tensor(train_inputs_oversample).to(device)\n",
    "                    train_labels_oversample = torch.tensor(train_labels_oversample).to(device)\n",
    "                    train_inputs_tensor = torch.cat((input_ids_tensor[train_index], train_inputs_oversample), dim=0)\n",
    "                    train_labels_tensor = torch.cat((labels_tensor[train_index], train_labels_oversample), dim=0)\n",
    "\n",
    "                # Print occurrences of each code after SMOTE\n",
    "                code_occurrences_after_smote = defaultdict(int)\n",
    "                for code in train_labels_tensor.cpu().numpy():\n",
    "                    code_occurrences_after_smote[code] += 1\n",
    "        \n",
    "                print(\"Code occurrences in the training data after Oversample:\")\n",
    "                for code, count in code_occurrences_after_smote.items():\n",
    "                    print(f\"{code}: {count}\")\n",
    "            else:\n",
    "                train_inputs_tensor = input_ids_tensor[train_index]\n",
    "                train_labels_tensor = labels_tensor[train_index]\n",
    "\n",
    "            train_masks = [[float(i != tokenizer.pad_token_id) for i in ii] for ii in train_inputs_tensor]\n",
    "\n",
    "            train_data = TensorDataset(train_inputs_tensor, torch.tensor(train_masks), train_labels_tensor)\n",
    "            train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n",
    "\n",
    "            validation_inputs, validation_masks = input_ids_tensor[val_index], torch.tensor(attention_masks)[val_index]\n",
    "            validation_labels = labels_tensor[val_index]\n",
    "\n",
    "            validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "            validation_dataloader = DataLoader(validation_data, sampler=SequentialSampler(validation_data), batch_size=batch_size)\n",
    "\n",
    "            precision, recall, f1 = train_and_evaluate_model(train_dataloader, validation_dataloader, num_epochs, learning_rate, device, fold, batch_size, oversample_method, cross_validation)\n",
    "\n",
    "            avg_precision += precision\n",
    "            avg_recall += recall\n",
    "            avg_f1 += f1\n",
    "\n",
    "            fold += 1\n",
    "\n",
    "        avg_precision /= 5\n",
    "        avg_recall /= 5\n",
    "        avg_f1 /= 5\n",
    "\n",
    "        print(f\"Average Precision across 5 folds: {avg_precision}\")\n",
    "        print(f\"Average Recall across 5 folds: {avg_recall}\")\n",
    "        print(f\"Average F1 Score across 5 folds: {avg_f1}\")\n",
    "\n",
    "        mlflow.log_metric(\"avg_precision\", avg_precision)\n",
    "        mlflow.log_metric(\"avg_recall\", avg_recall)\n",
    "        mlflow.log_metric(\"avg_f1\", avg_f1)\n",
    "\n",
    "        mlflow.end_run()\n",
    "\n",
    "    else:\n",
    "        # Split data into train and validation sets\n",
    "        train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids_tensor, labels_tensor, random_state=42, test_size=0.2)\n",
    "        train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids_tensor, random_state=42, test_size=0.2)\n",
    "\n",
    "        # Print occurrences of each code before SMOTE\n",
    "        code_occurrences_before_sampling = defaultdict(int)\n",
    "        for code in train_labels.cpu().numpy():\n",
    "            code_occurrences_before_sampling[code] += 1\n",
    "\n",
    "        print(\"Code occurrences in the training data:\")\n",
    "        for code, count in code_occurrences_before_sampling.items():\n",
    "            print(f\"{code}: {count}\")\n",
    "\n",
    "        if oversample_method:\n",
    "                # Apply SMOTE to training data for selected labels\n",
    "            if oversample_labels is not None:\n",
    "                oversample_indices = [i for i, label in enumerate(train_labels) if label in oversample_labels]\n",
    "                train_inputs_oversample, train_labels_oversample = train_inputs[oversample_indices], train_labels[oversample_indices]\n",
    "            else:\n",
    "                train_inputs_oversample, train_labels_oversample = train_inputs, train_labels\n",
    "    \n",
    "            if oversample_method == \"smote\":\n",
    "                oversampler = SMOTE(random_state=42)\n",
    "            elif oversample_method == \"adasyn\":\n",
    "                oversampler = ADASYN(sampling_strategy=\"auto\", random_state=42)\n",
    "            if oversample_labels==None:\n",
    "                train_inputs_oversample, train_labels_oversample = oversampler.fit_resample(train_inputs.cpu().numpy(), train_labels.cpu().numpy())\n",
    "                train_inputs = torch.tensor(train_inputs_oversample).to(device)\n",
    "                train_labels = torch.tensor(train_labels_oversample).to(device)\n",
    "                train_masks = [[float(i != tokenizer.pad_token_id) for i in ii] for ii in train_inputs]\n",
    "            else:\n",
    "                train_inputs_oversample, train_labels_oversample = oversampler.fit_resample(train_inputs_oversample.cpu().numpy(), train_labels_oversample.cpu().numpy())\n",
    "                train_inputs_oversample = torch.tensor(train_inputs_oversample).to(device)\n",
    "                train_labels_oversample = torch.tensor(train_labels_oversample).to(device)\n",
    "                train_inputs = torch.cat((train_inputs, train_inputs_oversample), dim=0)\n",
    "                train_labels = torch.cat((train_labels, train_labels_oversample), dim=0)\n",
    "                train_masks = [[float(i != tokenizer.pad_token_id) for i in ii] for ii in train_inputs]\n",
    "\n",
    "            # Print occurrences of each code after SMOTE\n",
    "            code_occurrences_after_smote = defaultdict(int)\n",
    "            for code in train_labels.cpu().numpy():\n",
    "                code_occurrences_after_smote[code] += 1\n",
    "\n",
    "            print(\"Code occurrences in the training data after Oversample:\")\n",
    "            for code, count in code_occurrences_after_smote.items():\n",
    "                print(f\"{code}: {count}\")\n",
    "    \n",
    "        # Convert to PyTorch dataset\n",
    "        train_data = TensorDataset(train_inputs, torch.tensor(train_masks), train_labels)\n",
    "        validation_data = TensorDataset(validation_inputs, torch.tensor(validation_masks).to(device), validation_labels)\n",
    "\n",
    "        # Create data loaders\n",
    "        train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n",
    "        validation_dataloader = DataLoader(validation_data, sampler=SequentialSampler(validation_data), batch_size=batch_size)\n",
    "\n",
    "        # Train and evaluate model\n",
    "        precision, recall, f1 = train_and_evaluate_model(train_dataloader, validation_dataloader, num_epochs, learning_rate, device, 1, batch_size, oversample_method, cross_validation) \n",
    "        \n",
    "        mlflow.end_run()\n",
    "\n",
    "    return\n",
    "\n",
    "def brennan_perediger_kappa(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    n = np.sum(cm)\n",
    "    pa = np.trace(cm) / n\n",
    "    pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / (n * n)\n",
    "    kappa = (pa - pe) / (1 - pe)\n",
    "    return kappa\n",
    "\n",
    "def train_and_evaluate_model(train_dataloader, validation_dataloader, num_epochs, learning_rate, device, fold, batch_size, oversample_method, cross_validation,):\n",
    "    total_steps = len(train_dataloader) * num_epochs\n",
    "\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=4).to(device)\n",
    "    #model = RobertaForSequenceClassification.from_pretrained('roberta-large', num_labels=3).to(device)\n",
    "\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    f1 = 0\n",
    "    precision_dict = defaultdict(float)\n",
    "    recall_dict = defaultdict(float)\n",
    "    f1_dict = defaultdict(float)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Running Epoch: {epoch+1}\")\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, masks, labels = [b.to(device) for b in batch]\n",
    "            outputs = model(inputs, attention_mask=masks, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        validation_labels_all = []\n",
    "        validation_preds_all = []\n",
    "\n",
    "        eval_start_time= time.time()\n",
    "\n",
    "        for batch in validation_dataloader:\n",
    "            inputs, masks, labels = [b.to(device) for b in batch]\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs, attention_mask=masks)\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            validation_labels_all.extend(labels.cpu().numpy())\n",
    "            validation_preds_all.extend(preds.cpu().numpy())\n",
    "\n",
    "        eval_end_time = time.time()\n",
    "        eval_runtime = eval_end_time - eval_start_time\n",
    "\n",
    "        # Calculate precision, recall, and F1 score for each label\n",
    "\n",
    "        for label in range(4):\n",
    "            precision_dict[label] = precision_score(validation_labels_all, validation_preds_all, labels=[label], average=None, zero_division=0)\n",
    "            recall_dict[label] = recall_score(validation_labels_all, validation_preds_all, labels=[label], average=None)\n",
    "            f1_dict[label] = f1_score(validation_labels_all, validation_preds_all, labels=[label], average=None)\n",
    "\n",
    "            # Calculate overall precision, recall, and F1 score\n",
    "            precision = precision_score(validation_labels_all, validation_preds_all, average=\"weighted\", zero_division=0)\n",
    "            recall = recall_score(validation_labels_all, validation_preds_all, average=\"weighted\")\n",
    "            f1 = f1_score(validation_labels_all, validation_preds_all, average=\"weighted\")\n",
    "\n",
    "            kappa = brennan_perediger_kappa(validation_labels_all, validation_preds_all)\n",
    "\n",
    "        avg_val_loss = total_loss / len(validation_dataloader)\n",
    "\n",
    "        print(f\"Precision_epoch{epoch}: {precision}\")\n",
    "        print(f\"Recall_epoch{epoch}: {recall}\")\n",
    "        print(f\"F1_epoch{epoch}: {f1}\")\n",
    "        print(f\"Kappa_epoch{epoch}: {kappa}\")\n",
    "        print(f\"AvgTrainLoss_epoch{epoch}: {avg_train_loss}\")\n",
    "        print(f\"AvgValLoss_epoch{epoch}: {avg_val_loss}\")\n",
    "        print(f\"Eval_Runtime_epoch{epoch}: {eval_runtime}\")\n",
    "        \n",
    "    with mlflow.start_run():\n",
    "        # Log precision, recall, and F1 score for each label to MLFlow\n",
    "        for label in range(4):\n",
    "            mlflow.log_metric(f\"ToreLabel_{label}_precision_fold{fold}\", precision_dict[label])\n",
    "            mlflow.log_metric(f\"ToreLabel_{label}_recall_fold{fold}\", recall_dict[label])\n",
    "            mlflow.log_metric(f\"ToreLabel_{label}_f1_fold{fold}\", f1_dict[label])\n",
    "            #mlflow.log_artifact(f'confusion_matrix_{fold}')\n",
    "\n",
    "        # Log overall precision, recall, and F1 score to MLFlow\n",
    "        mlflow.log_metric(f\"precision_fold{fold}\", precision)\n",
    "        mlflow.log_metric(f\"recall_fold{fold}\", recall)\n",
    "        mlflow.log_metric(f\"f1_fold{fold}\", f1)\n",
    "        mlflow.log_metric(f\"kappa_fold{fold}\", kappa)\n",
    "        mlflow.log_param(\"num_epochs\", num_epochs)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"smote\", oversample_method)\n",
    "        mlflow.log_param(\"cross_validation\", cross_validation)\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "\n",
    "train_model(\"E:/BERT/uvl-tore-classifier-bert/src/data/datasets/smartage/SmartAgeTore.json\", num_epochs=1, learning_rate=3e-05, batch_size=64, oversample_method=False, oversample_labels=None, cross_validation=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T14:46:46.302116Z",
     "start_time": "2024-06-13T14:32:56.937239Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    " #Questions as Classification Feature:"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T10:53:46.657191Z",
     "start_time": "2024-05-28T10:53:46.654191Z"
    }
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\BERT\\uvl-tore-classifier-bert\\venv310\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code occurrences in the training data:\n",
      "2: 455\n",
      "0: 900\n",
      "1: 1671\n",
      "3: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "E:\\BERT\\uvl-tore-classifier-bert\\venv310\\lib\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.10\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\BERT\\uvl-tore-classifier-bert\\venv310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision: 0.34\n",
      "  Recall: 0.51\n",
      "  F1: 0.35\n",
      "\n",
      "======== Epoch 2 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 1.02\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\BERT\\uvl-tore-classifier-bert\\venv310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision: 0.54\n",
      "  Recall: 0.56\n",
      "  F1: 0.46\n",
      "\n",
      "======== Epoch 3 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.89\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\BERT\\uvl-tore-classifier-bert\\venv310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision: 0.55\n",
      "  Recall: 0.67\n",
      "  F1: 0.61\n",
      "\n",
      "======== Epoch 4 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.73\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\BERT\\uvl-tore-classifier-bert\\venv310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision: 0.72\n",
      "  Recall: 0.75\n",
      "  F1: 0.73\n",
      "\n",
      "======== Epoch 5 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.54\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\BERT\\uvl-tore-classifier-bert\\venv310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision: 0.73\n",
      "  Recall: 0.76\n",
      "  F1: 0.74\n",
      "\n",
      "======== Epoch 6 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.43\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\BERT\\uvl-tore-classifier-bert\\venv310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Precision: 0.75\n",
      "  Recall: 0.75\n",
      "  F1: 0.73\n",
      "\n",
      "======== Epoch 7 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.32\n",
      "\n",
      "Running Validation...\n",
      "  Precision: 0.78\n",
      "  Recall: 0.76\n",
      "  F1: 0.76\n",
      "\n",
      "======== Epoch 8 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.22\n",
      "\n",
      "Running Validation...\n",
      "  Precision: 0.78\n",
      "  Recall: 0.78\n",
      "  F1: 0.77\n",
      "\n",
      "======== Epoch 9 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.16\n",
      "\n",
      "Running Validation...\n",
      "  Precision: 0.78\n",
      "  Recall: 0.77\n",
      "  F1: 0.77\n",
      "\n",
      "======== Epoch 10 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.14\n",
      "\n",
      "Running Validation...\n",
      "  Precision: 0.78\n",
      "  Recall: 0.76\n",
      "  F1: 0.77\n",
      "\n",
      "======== Epoch 11 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.09\n",
      "\n",
      "Running Validation...\n",
      "  Precision: 0.78\n",
      "  Recall: 0.76\n",
      "  F1: 0.77\n",
      "\n",
      "======== Epoch 12 / 12 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.08\n",
      "\n",
      "Running Validation...\n",
      "  Precision: 0.77\n",
      "  Recall: 0.77\n",
      "  F1: 0.77\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "import json\n",
    "import mlflow\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "\n",
    "def train_model(data_path, num_epochs, learning_rate, batch_size, oversample_method=False, oversample_labels=None, cross_validation=False):\n",
    "    # Set MLFlow experiment name\n",
    "    mlflow.set_experiment(\"SentenceClass\")\n",
    "\n",
    "    # Check if CUDA is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('Using device:', device)\n",
    "\n",
    "    # Load BERT tokenizer\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "\n",
    "    # Read the JSON file\n",
    "    def read_json(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        return data\n",
    "\n",
    "    data = read_json(data_path)\n",
    "\n",
    "    # Extract sentences, questions, and labels\n",
    "    sentences = [token['name'] for token in data['tokens']]\n",
    "    questions = [token['question'] for token in data['tokens']]\n",
    "    labels = [code['tore'] for code in data['codes']]\n",
    "    label_mapping = {'0': 0, 'Domain Level': 1, 'Interaction Level': 2, 'System Level': 3}\n",
    "    labels = [label_mapping[label] if label in label_mapping else label for label in labels]\n",
    "\n",
    "    # Concatenate questions with sentences\n",
    "    combined_texts = [f\"Question: {q} Answer: {s}\" for q, s in zip(questions, sentences)]\n",
    "\n",
    "    # Tokenize input sentences\n",
    "    tokenized_texts = [tokenizer.tokenize(text) for text in combined_texts]\n",
    "\n",
    "    # Convert tokens to input IDs\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "\n",
    "    # Pad input sequences\n",
    "    max_len = max(len(x) for x in input_ids)\n",
    "    padded_input_ids = [x + [tokenizer.pad_token_id] * (max_len - len(x)) for x in input_ids]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    input_ids_tensor = torch.tensor(padded_input_ids).to(device)\n",
    "    labels_tensor = torch.tensor(labels).to(device)\n",
    "\n",
    "    # Create attention masks\n",
    "    attention_masks = [[float(i != tokenizer.pad_token_id) for i in ii] for ii in padded_input_ids]\n",
    "\n",
    "    if cross_validation:\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        fold = 1\n",
    "        avg_precision = 0\n",
    "        avg_recall = 0\n",
    "        avg_f1 = 0\n",
    "\n",
    "        for train_index, val_index in kf.split(input_ids_tensor):\n",
    "            print(f\"Fold {fold}\")\n",
    "\n",
    "            if oversample_method:\n",
    "                # Apply SMOTE to training data for selected labels\n",
    "                if oversample_labels is not None:\n",
    "                    oversample_indices = [i for i, label in enumerate(labels_tensor[train_index]) if label in oversample_labels]\n",
    "                    train_inputs_oversample, train_labels_oversample = input_ids_tensor[train_index][oversample_indices], labels_tensor[train_index][oversample_indices]\n",
    "                else:\n",
    "                    train_inputs_oversample, train_labels_oversample = input_ids_tensor[train_index], labels_tensor[train_index]\n",
    "\n",
    "                if oversample_method == \"smote\":\n",
    "                    oversampler = SMOTE(random_state=42)\n",
    "                elif oversample_method == \"adasyn\":\n",
    "                    oversampler = ADASYN(random_state=42)\n",
    "                if oversample_labels==None:\n",
    "                    train_inputs_smote, train_labels_smote = oversampler.fit_resample(input_ids_tensor[train_index], labels_tensor[train_index])\n",
    "                    train_inputs_tensor = torch.tensor(train_inputs_smote).to(device)\n",
    "                    train_labels_tensor = torch.tensor(train_labels_smote).to(device)\n",
    "                else:\n",
    "                    train_inputs_oversample, train_labels_oversample = oversampler.fit_resample(train_inputs_oversample.cpu().numpy(), train_labels_oversample.cpu().numpy())\n",
    "                    train_inputs_oversample = torch.tensor(train_inputs_oversample).to(device)\n",
    "                    train_labels_oversample = torch.tensor(train_labels_oversample).to(device)\n",
    "                    train_inputs_tensor = torch.cat((input_ids_tensor[train_index], train_inputs_oversample), dim=0)\n",
    "                    train_labels_tensor = torch.cat((labels_tensor[train_index], train_labels_oversample), dim=0)\n",
    "\n",
    "                # Print occurrences of each code after SMOTE\n",
    "                code_occurrences_after_smote = defaultdict(int)\n",
    "                for code in train_labels_tensor.cpu().numpy():\n",
    "                    code_occurrences_after_smote[code] += 1\n",
    "\n",
    "                print(\"Code occurrences in the training data after Oversample:\")\n",
    "                for code, count in code_occurrences_after_smote.items():\n",
    "                    print(f\"{code}: {count}\")\n",
    "            else:\n",
    "                train_inputs_tensor = input_ids_tensor[train_index]\n",
    "                train_labels_tensor = labels_tensor[train_index]\n",
    "\n",
    "            train_masks = [[float(i != tokenizer.pad_token_id) for i in ii] for ii in train_inputs_tensor]\n",
    "\n",
    "            train_data = TensorDataset(train_inputs_tensor, torch.tensor(train_masks), train_labels_tensor)\n",
    "            train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n",
    "\n",
    "            validation_inputs, validation_masks = input_ids_tensor[val_index], torch.tensor(attention_masks)[val_index]\n",
    "            validation_labels = labels_tensor[val_index]\n",
    "\n",
    "            validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "            validation_dataloader = DataLoader(validation_data, sampler=SequentialSampler(validation_data), batch_size=batch_size)\n",
    "\n",
    "            precision, recall, f1 = train_and_evaluate_model(train_dataloader, validation_dataloader, num_epochs, learning_rate, device, fold, batch_size, smote, cross_validation)\n",
    "\n",
    "            avg_precision += precision\n",
    "            avg_recall += recall\n",
    "            avg_f1 += f1\n",
    "\n",
    "            fold += 1\n",
    "\n",
    "        avg_precision /= 5\n",
    "        avg_recall /= 5\n",
    "        avg_f1 /= 5\n",
    "\n",
    "        print(f\"Average Precision across 5 folds: {avg_precision}\")\n",
    "        print(f\"Average Recall across 5 folds: {avg_recall}\")\n",
    "        print(f\"Average F1 Score across 5 folds: {avg_f1}\")\n",
    "\n",
    "        mlflow.log_metric(\"avg_precision\", avg_precision)\n",
    "        mlflow.log_metric(\"avg_recall\", avg_recall)\n",
    "        mlflow.log_metric(\"avg_f1\", avg_f1)\n",
    "\n",
    "        mlflow.end_run()\n",
    "\n",
    "    else:\n",
    "        # Split data into train and validation sets\n",
    "        train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids_tensor, labels_tensor, random_state=42, test_size=0.2)\n",
    "        train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids_tensor, random_state=42, test_size=0.2)\n",
    "\n",
    "        # Print occurrences of each code before SMOTE\n",
    "        code_occurrences_before_sampling = defaultdict(int)\n",
    "        for code in train_labels.cpu().numpy():\n",
    "            code_occurrences_before_sampling[code] += 1\n",
    "\n",
    "        print(\"Code occurrences in the training data:\")\n",
    "        for code, count in code_occurrences_before_sampling.items():\n",
    "            print(f\"{code}: {count}\")\n",
    "\n",
    "        if oversample_method:\n",
    "            # Apply SMOTE to training data for selected labels\n",
    "            if oversample_labels is not None:\n",
    "                oversample_indices = [i for i, label in enumerate(train_labels) if label in oversample_labels]\n",
    "                train_inputs_oversample, train_labels_oversample = train_inputs[oversample_indices], train_labels[oversample_indices]\n",
    "            else:\n",
    "                train_inputs_oversample, train_labels_oversample = train_inputs, train_labels\n",
    "\n",
    "            if oversample_method == \"smote\":\n",
    "                oversampler = SMOTE(random_state=42)\n",
    "            elif oversample_method == \"adasyn\":\n",
    "                oversampler = ADASYN(sampling_strategy=\"auto\", random_state=42)\n",
    "            if oversample_labels == None:\n",
    "                train_inputs_oversample, train_labels_oversample = oversampler.fit_resample(train_inputs.cpu().numpy(), train_labels.cpu().numpy())\n",
    "                train_inputs = torch.tensor(train_inputs_oversample).to(device)\n",
    "                train_labels = torch.tensor(train_labels_oversample).to(device)\n",
    "                train_masks = [[float(i != tokenizer.pad_token_id) for i in ii] for ii in train_inputs]\n",
    "            else:\n",
    "                train_inputs_oversample, train_labels_oversample = oversampler.fit_resample(train_inputs_oversample.cpu().numpy(), train_labels_oversample.cpu().numpy())\n",
    "                train_inputs_oversample = torch.tensor(train_inputs_oversample).to(device)\n",
    "                train_labels_oversample = torch.tensor(train_labels_oversample).to(device)\n",
    "                train_inputs = torch.cat((train_inputs, train_inputs_oversample), dim=0)\n",
    "                train_labels = torch.cat((train_labels, train_labels_oversample), dim=0)\n",
    "                train_masks = [[float(i != tokenizer.pad_token_id) for i in ii] for ii in train_inputs]\n",
    "\n",
    "            # Print occurrences of each code after SMOTE\n",
    "            code_occurrences_after_smote = defaultdict(int)\n",
    "            for code in train_labels.cpu().numpy():\n",
    "                code_occurrences_after_smote[code] += 1\n",
    "\n",
    "            print(\"Code occurrences in the training data after Oversample:\")\n",
    "            for code, count in code_occurrences_after_smote.items():\n",
    "                print(f\"{code}: {count}\")\n",
    "\n",
    "        # Convert to tensors\n",
    "        train_masks = torch.tensor(train_masks)\n",
    "        validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "        train_dataloader = DataLoader(train_data, sampler=RandomSampler(train_data), batch_size=batch_size)\n",
    "\n",
    "        validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "        validation_dataloader = DataLoader(validation_data, sampler=SequentialSampler(validation_data), batch_size=batch_size)\n",
    "\n",
    "        train_and_evaluate_model(train_dataloader, validation_dataloader, num_epochs, learning_rate, device, None, batch_size, oversample_method, cross_validation)\n",
    "\n",
    "def train_and_evaluate_model(train_dataloader, validation_dataloader, num_epochs, learning_rate, device, fold, batch_size, smote, cross_validation):\n",
    "    model = BertForSequenceClassification.from_pretrained('bert-large-uncased', num_labels=4)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "\n",
    "    total_steps = len(train_dataloader) * num_epochs\n",
    "\n",
    "    training_stats = []\n",
    "\n",
    "    for epoch_i in range(0, num_epochs):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, num_epochs))\n",
    "        print('Training...')\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        total_loss = 0\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        eval_loss, eval_accuracy = 0, 0\n",
    "        nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "        true_labels, predictions = [], []\n",
    "\n",
    "        for batch in validation_dataloader:\n",
    "            b_input_ids = batch[0].to(device)\n",
    "            b_input_mask = batch[1].to(device)\n",
    "            b_labels = batch[2].to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "            logits = outputs.logits\n",
    "\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "            predictions.append(logits)\n",
    "            true_labels.append(label_ids)\n",
    "\n",
    "        flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "        flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "\n",
    "        flat_predictions = np.argmax(flat_predictions, axis=1)\n",
    "\n",
    "        precision = precision_score(flat_true_labels, flat_predictions, average='weighted')\n",
    "        recall = recall_score(flat_true_labels, flat_predictions, average='weighted')\n",
    "        f1 = f1_score(flat_true_labels, flat_predictions, average='weighted')\n",
    "\n",
    "        print(\"  Precision: {0:.2f}\".format(precision))\n",
    "        print(\"  Recall: {0:.2f}\".format(recall))\n",
    "        print(\"  F1: {0:.2f}\".format(f1))\n",
    "\n",
    "        training_stats.append({\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1': f1\n",
    "        })\n",
    "\n",
    "        mlflow.log_metric(\"train_loss_epoch\", avg_train_loss, step=epoch_i)\n",
    "        mlflow.log_metric(\"precision_fold1\", precision, step=epoch_i)\n",
    "        mlflow.log_metric(\"recall_fold1\", recall, step=epoch_i)\n",
    "        mlflow.log_metric(\"f1_fold1\", f1, step=epoch_i)\n",
    "\n",
    "        if fold is not None:\n",
    "            mlflow.log_metric(f\"precision_fold_{fold}_epoch_{epoch_i + 1}\", precision)\n",
    "            mlflow.log_metric(f\"recall_fold_{fold}_epoch_{epoch_i + 1}\", recall)\n",
    "            mlflow.log_metric(f\"f1_fold_{fold}_epoch_{epoch_i + 1}\", f1)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Example usage\n",
    "data_path = 'C:/Users/mjand/Seafile/Meine Bibliothek/SmartAge/SmartAgeToreWithQuestions.json'\n",
    "train_model(data_path, num_epochs=12, learning_rate=3e-05, batch_size=64, oversample_method=False, oversample_labels=None, cross_validation=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-28T13:17:52.414941Z",
     "start_time": "2024-05-28T11:05:29.401586Z"
    }
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
